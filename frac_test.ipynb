{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fx(x):\n",
    "    return np.sum(x**2)\n",
    "    \n",
    "def grad(f, x, epsilon=0.0001):\n",
    "    g = np.zeros((x.shape[0],) )\n",
    "\n",
    "    x_temp = x.copy()\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        x_temp[i] += epsilon\n",
    "        if i>0:\n",
    "            x_temp[i-1] -= epsilon\n",
    "        g[i] = ((f(x_temp) - f(x)) / epsilon) \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(f, x0, lr=0.1, max_iter=500, return_history=False):\n",
    "    x = x0\n",
    "    history = [x]\n",
    "    for i in range(max_iter):\n",
    "        x_new = x - lr * grad(f, x)\n",
    "\n",
    "        if f(x_new) < f(x):\n",
    "            x = x_new\n",
    "        else:\n",
    "            print(f\"Updating learning rate: {lr}\")\n",
    "            lr = 0.8*lr\n",
    "            if lr < 0.1 ** 12:\n",
    "                print(\"Early STOP!!!\")\n",
    "                break\n",
    "            \n",
    "        history.append(x)\n",
    "    if return_history:\n",
    "        return x, history\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frac_optimizer(f, x0, lr=0.5, alpha=0.98, max_iter=1000, return_history=False):\n",
    "    x = x0\n",
    "    history = [x]\n",
    "    x_new = x - lr * grad(f, x)\n",
    "    history.append(x_new)\n",
    "    indx = 0\n",
    "    for i in range(max_iter):\n",
    "       \n",
    "        x_new_new = history[indx+1] - (lr/gamma(2-alpha)) * grad(f, history[indx]) * np.abs(history[indx+1] - history[indx]) ** (1-alpha)\n",
    "        if f(x_new_new) < f(history[indx+1]):\n",
    "            history.append(x_new_new)\n",
    "            indx += 1\n",
    "        else:\n",
    "            \n",
    "            print(f\"Updating learning rate: {lr}\")\n",
    "            lr = 0.8*lr\n",
    "            if lr < 0.1 ** 12:\n",
    "                print(\"Early STOP!!!\")\n",
    "                break\n",
    "        # history.append(x)\n",
    "        # print(x)\n",
    "    if return_history:\n",
    "        return history[-1], history\n",
    "    else:\n",
    "        return history[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_frac_optimizer(f, x0, lr=0.5, alpha1=0.9, alpha2=1.1, max_iter=1000, return_history=False):\n",
    "    x = x0\n",
    "    history = [x]\n",
    "    x_new = x - lr * grad(f, x)\n",
    "    history.append(x_new)\n",
    "    indx = 0\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        t1 = (1/gamma(2-alpha1)) * grad(f, history[indx]) * np.abs(history[indx+1] - history[indx]) ** (1- alpha1)\n",
    "        t2 = (1/gamma(2-alpha2)) * grad(f, history[indx]) * np.abs(history[indx+1] - history[indx]) ** (1- alpha2)\n",
    "       \n",
    "        x_new_new = history[indx+1] - lr*(0.5*t1 + 0.5*t2)\n",
    "        if f(x_new_new) < f(history[indx+1]):\n",
    "            history.append(x_new_new)\n",
    "            indx += 1\n",
    "        else:\n",
    "            \n",
    "            print(f\"Updating learning rate: {lr}\")\n",
    "            lr = 0.8*lr\n",
    "            if lr < 0.1 ** 12:\n",
    "                print(\"Early STOP!!!\")\n",
    "                break\n",
    "        # history.append(x)\n",
    "        # print(x)\n",
    "    if return_history:\n",
    "        return history[-1], history\n",
    "    else:\n",
    "        return history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_frac_optimizer(f, x0, lr=0.5, alpha1=0.9, alpha2=1.1, N=50, max_iter=1000, return_history=False):\n",
    "    x = x0\n",
    "    history = [x]\n",
    "    x_new = x - lr * grad(f, x)\n",
    "    history.append(x_new)\n",
    "    indx = 0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        d_alpha = (alpha2-alpha1)/N\n",
    "        \n",
    "        # d = lambda alpha: (1/gamma(2-alpha)) * grad(f, history[indx]) * np.abs(history[indx+1] - history[indx]) ** (1-alpha)\n",
    "        d = lambda alpha: ((2*(alpha-alpha1))/(gamma(2-alpha)*(alpha2-alpha1)**2)) * grad(f, history[indx]) * np.abs(history[indx+1] - history[indx]) ** (1-alpha)\n",
    "\n",
    "        delta = 0.5*d(alpha1)\n",
    "        for n in range(1, N):\n",
    "            delta = delta + d(alpha1 + n*d_alpha)\n",
    "        delta = 0.5*d(alpha2)\n",
    "\n",
    "        x_new_new = history[indx+1] - lr*delta\n",
    "        if f(x_new_new) < f(history[indx+1]):\n",
    "            history.append(x_new_new)\n",
    "            indx += 1\n",
    "        else:\n",
    "            \n",
    "            print(f\"Updating learning rate: {lr}\")\n",
    "            lr = 0.8*lr\n",
    "            if lr < 0.1 ** 12:\n",
    "                print(\"Early STOP!!!\")\n",
    "                break\n",
    "        # history.append(x)\n",
    "        # print(x)\n",
    "    if return_history:\n",
    "        return history[-1], history\n",
    "    else:\n",
    "        return history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 10*np.ones((200, )) + np.random.random((200, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate: 0.05\n",
      "Updating learning rate: 0.04000000000000001\n",
      "Updating learning rate: 0.03200000000000001\n",
      "Updating learning rate: 0.025600000000000008\n",
      "Updating learning rate: 0.02048000000000001\n",
      "Updating learning rate: 0.016384000000000006\n",
      "Updating learning rate: 0.013107200000000006\n",
      "Updating learning rate: 0.010485760000000005\n",
      "Updating learning rate: 0.008388608000000004\n",
      "Updating learning rate: 0.006710886400000004\n",
      "Updating learning rate: 0.005368709120000003\n",
      "Updating learning rate: 0.0042949672960000025\n",
      "Updating learning rate: 0.0034359738368000023\n",
      "Updating learning rate: 0.002748779069440002\n",
      "Updating learning rate: 0.002199023255552002\n",
      "Updating learning rate: 0.0017592186044416017\n",
      "Updating learning rate: 0.0014073748835532814\n",
      "Updating learning rate: 0.0011258999068426252\n",
      "Updating learning rate: 0.0009007199254741002\n",
      "Updating learning rate: 0.0007205759403792802\n",
      "Updating learning rate: 0.0005764607523034242\n",
      "Updating learning rate: 0.00046116860184273935\n",
      "Updating learning rate: 0.0003689348814741915\n",
      "Updating learning rate: 0.00029514790517935324\n",
      "Updating learning rate: 0.0002361183241434826\n",
      "Updating learning rate: 0.0001888946593147861\n",
      "Updating learning rate: 0.00015111572745182887\n",
      "Updating learning rate: 0.0001208925819614631\n",
      "Updating learning rate: 9.671406556917049e-05\n",
      "Updating learning rate: 7.73712524553364e-05\n",
      "Updating learning rate: 6.189700196426911e-05\n",
      "Updating learning rate: 4.9517601571415295e-05\n",
      "Updating learning rate: 3.961408125713224e-05\n",
      "Updating learning rate: 3.1691265005705794e-05\n",
      "Updating learning rate: 2.5353012004564636e-05\n",
      "Updating learning rate: 2.028240960365171e-05\n",
      "Updating learning rate: 1.6225927682921368e-05\n",
      "Updating learning rate: 1.2980742146337096e-05\n",
      "Updating learning rate: 1.0384593717069677e-05\n",
      "Updating learning rate: 8.307674973655742e-06\n",
      "Updating learning rate: 6.646139978924594e-06\n",
      "Updating learning rate: 5.3169119831396756e-06\n",
      "Updating learning rate: 4.2535295865117404e-06\n",
      "Updating learning rate: 3.4028236692093925e-06\n",
      "Updating learning rate: 2.722258935367514e-06\n",
      "Updating learning rate: 2.1778071482940113e-06\n",
      "Updating learning rate: 1.7422457186352091e-06\n",
      "Updating learning rate: 1.3937965749081673e-06\n",
      "Updating learning rate: 1.1150372599265338e-06\n",
      "Updating learning rate: 8.920298079412272e-07\n",
      "Updating learning rate: 7.136238463529817e-07\n",
      "Updating learning rate: 5.708990770823854e-07\n",
      "Updating learning rate: 4.567192616659084e-07\n",
      "Updating learning rate: 3.6537540933272675e-07\n",
      "Updating learning rate: 2.9230032746618143e-07\n",
      "Updating learning rate: 2.3384026197294516e-07\n",
      "Updating learning rate: 1.8707220957835615e-07\n",
      "Updating learning rate: 1.4965776766268494e-07\n",
      "Updating learning rate: 1.1972621413014797e-07\n",
      "Updating learning rate: 9.578097130411838e-08\n",
      "Updating learning rate: 7.662477704329471e-08\n",
      "Updating learning rate: 6.129982163463577e-08\n",
      "Updating learning rate: 4.903985730770862e-08\n",
      "Updating learning rate: 3.92318858461669e-08\n",
      "Updating learning rate: 3.138550867693352e-08\n",
      "Updating learning rate: 2.510840694154682e-08\n",
      "Updating learning rate: 2.0086725553237457e-08\n",
      "Updating learning rate: 1.6069380442589967e-08\n",
      "Updating learning rate: 1.2855504354071975e-08\n",
      "Updating learning rate: 1.028440348325758e-08\n",
      "Updating learning rate: 8.227522786606064e-09\n",
      "Updating learning rate: 6.582018229284852e-09\n",
      "Updating learning rate: 5.265614583427882e-09\n",
      "Updating learning rate: 4.2124916667423055e-09\n",
      "Updating learning rate: 3.3699933333938447e-09\n",
      "Updating learning rate: 2.6959946667150758e-09\n",
      "Updating learning rate: 2.1567957333720605e-09\n",
      "Updating learning rate: 1.7254365866976486e-09\n",
      "Updating learning rate: 1.380349269358119e-09\n",
      "Updating learning rate: 1.1042794154864951e-09\n",
      "Updating learning rate: 8.834235323891962e-10\n",
      "Updating learning rate: 7.06738825911357e-10\n",
      "Updating learning rate: 5.653910607290857e-10\n",
      "Updating learning rate: 4.523128485832686e-10\n",
      "Updating learning rate: 3.6185027886661486e-10\n",
      "Updating learning rate: 2.894802230932919e-10\n",
      "Updating learning rate: 2.3158417847463353e-10\n",
      "Updating learning rate: 1.8526734277970683e-10\n",
      "Updating learning rate: 1.4821387422376549e-10\n",
      "Updating learning rate: 1.185710993790124e-10\n",
      "Updating learning rate: 9.485687950320993e-11\n",
      "Updating learning rate: 7.588550360256795e-11\n",
      "Updating learning rate: 6.070840288205436e-11\n",
      "Updating learning rate: 4.8566722305643496e-11\n",
      "Updating learning rate: 3.88533778445148e-11\n",
      "Updating learning rate: 3.108270227561184e-11\n",
      "Updating learning rate: 2.4866161820489475e-11\n",
      "Updating learning rate: 1.989292945639158e-11\n",
      "Updating learning rate: 1.5914343565113267e-11\n",
      "Updating learning rate: 1.2731474852090614e-11\n",
      "Updating learning rate: 1.0185179881672492e-11\n",
      "Updating learning rate: 8.148143905337994e-12\n",
      "Updating learning rate: 6.5185151242703956e-12\n",
      "Updating learning rate: 5.214812099416317e-12\n",
      "Updating learning rate: 4.171849679533054e-12\n",
      "Updating learning rate: 3.3374797436264432e-12\n",
      "Updating learning rate: 2.6699837949011546e-12\n",
      "Updating learning rate: 2.135987035920924e-12\n",
      "Updating learning rate: 1.7087896287367392e-12\n",
      "Updating learning rate: 1.3670317029893914e-12\n",
      "Updating learning rate: 1.0936253623915131e-12\n",
      "Early STOP!!!\n",
      "CPU times: total: 422 ms\n",
      "Wall time: 440 ms\n"
     ]
    }
   ],
   "source": [
    "%time x, history_int = optimizer(fx, x0, lr=0.05, return_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate: 0.03\n",
      "Updating learning rate: 0.024\n",
      "Updating learning rate: 0.019200000000000002\n",
      "Updating learning rate: 0.015360000000000002\n",
      "Updating learning rate: 0.012288000000000002\n",
      "Updating learning rate: 0.009830400000000003\n",
      "Updating learning rate: 0.007864320000000003\n",
      "Updating learning rate: 0.0062914560000000026\n",
      "Updating learning rate: 0.005033164800000003\n",
      "Updating learning rate: 0.004026531840000003\n",
      "Updating learning rate: 0.0032212254720000023\n",
      "Updating learning rate: 0.002576980377600002\n",
      "Updating learning rate: 0.0020615843020800016\n",
      "Updating learning rate: 0.0016492674416640014\n",
      "Updating learning rate: 0.0013194139533312013\n",
      "Updating learning rate: 0.001055531162664961\n",
      "Updating learning rate: 0.0008444249301319689\n",
      "Updating learning rate: 0.0006755399441055751\n",
      "Updating learning rate: 0.0005404319552844601\n",
      "Updating learning rate: 0.0004323455642275681\n",
      "Updating learning rate: 0.0003458764513820545\n",
      "Updating learning rate: 0.0002767011611056436\n",
      "Updating learning rate: 0.0002213609288845149\n",
      "Updating learning rate: 0.00017708874310761193\n",
      "Updating learning rate: 0.00014167099448608955\n",
      "Updating learning rate: 0.00011333679558887165\n",
      "Updating learning rate: 9.066943647109732e-05\n",
      "Updating learning rate: 7.253554917687786e-05\n",
      "Updating learning rate: 5.802843934150229e-05\n",
      "Updating learning rate: 4.642275147320184e-05\n",
      "Updating learning rate: 3.7138201178561476e-05\n",
      "Updating learning rate: 2.9710560942849182e-05\n",
      "Updating learning rate: 2.376844875427935e-05\n",
      "Updating learning rate: 1.901475900342348e-05\n",
      "Updating learning rate: 1.5211807202738786e-05\n",
      "Updating learning rate: 1.216944576219103e-05\n",
      "Updating learning rate: 9.735556609752823e-06\n",
      "Updating learning rate: 7.788445287802259e-06\n",
      "Updating learning rate: 6.230756230241808e-06\n",
      "Updating learning rate: 4.984604984193447e-06\n",
      "Updating learning rate: 3.987683987354758e-06\n",
      "Updating learning rate: 3.1901471898838066e-06\n",
      "Updating learning rate: 2.5521177519070454e-06\n",
      "Updating learning rate: 2.0416942015256364e-06\n",
      "Updating learning rate: 1.6333553612205092e-06\n",
      "Updating learning rate: 1.3066842889764074e-06\n",
      "Updating learning rate: 1.045347431181126e-06\n",
      "Updating learning rate: 8.362779449449008e-07\n",
      "Updating learning rate: 6.690223559559207e-07\n",
      "Updating learning rate: 5.352178847647365e-07\n",
      "Updating learning rate: 4.2817430781178924e-07\n",
      "Updating learning rate: 3.425394462494314e-07\n",
      "Updating learning rate: 2.7403155699954515e-07\n",
      "Updating learning rate: 2.1922524559963614e-07\n",
      "Updating learning rate: 1.7538019647970893e-07\n",
      "Updating learning rate: 1.4030415718376716e-07\n",
      "Updating learning rate: 1.1224332574701373e-07\n",
      "Updating learning rate: 8.9794660597611e-08\n",
      "Updating learning rate: 7.18357284780888e-08\n",
      "Updating learning rate: 5.746858278247104e-08\n",
      "Updating learning rate: 4.597486622597683e-08\n",
      "Updating learning rate: 3.677989298078147e-08\n",
      "Updating learning rate: 2.9423914384625176e-08\n",
      "Updating learning rate: 2.3539131507700142e-08\n",
      "Updating learning rate: 1.8831305206160116e-08\n",
      "Updating learning rate: 1.5065044164928095e-08\n",
      "Updating learning rate: 1.2052035331942477e-08\n",
      "Updating learning rate: 9.641628265553983e-09\n",
      "Updating learning rate: 7.713302612443187e-09\n",
      "Updating learning rate: 6.1706420899545494e-09\n",
      "Updating learning rate: 4.93651367196364e-09\n",
      "Updating learning rate: 3.949210937570912e-09\n",
      "Updating learning rate: 3.1593687500567297e-09\n",
      "Updating learning rate: 2.527495000045384e-09\n",
      "Updating learning rate: 2.0219960000363072e-09\n",
      "Updating learning rate: 1.617596800029046e-09\n",
      "Updating learning rate: 1.2940774400232369e-09\n",
      "Updating learning rate: 1.0352619520185895e-09\n",
      "Updating learning rate: 8.282095616148717e-10\n",
      "Updating learning rate: 6.625676492918974e-10\n",
      "Updating learning rate: 5.30054119433518e-10\n",
      "Updating learning rate: 4.2404329554681437e-10\n",
      "Updating learning rate: 3.392346364374515e-10\n",
      "Updating learning rate: 2.713877091499612e-10\n",
      "Updating learning rate: 2.1711016731996896e-10\n",
      "Updating learning rate: 1.7368813385597518e-10\n",
      "Updating learning rate: 1.3895050708478016e-10\n",
      "Updating learning rate: 1.1116040566782413e-10\n",
      "Updating learning rate: 8.892832453425931e-11\n",
      "Updating learning rate: 7.114265962740745e-11\n",
      "Updating learning rate: 5.691412770192596e-11\n",
      "Updating learning rate: 4.553130216154077e-11\n",
      "Updating learning rate: 3.642504172923262e-11\n",
      "Updating learning rate: 2.91400333833861e-11\n",
      "Updating learning rate: 2.331202670670888e-11\n",
      "Updating learning rate: 1.8649621365367104e-11\n",
      "Updating learning rate: 1.4919697092293683e-11\n",
      "Updating learning rate: 1.1935757673834948e-11\n",
      "Updating learning rate: 9.548606139067959e-12\n",
      "Updating learning rate: 7.638884911254367e-12\n",
      "Updating learning rate: 6.111107929003494e-12\n",
      "Updating learning rate: 4.888886343202796e-12\n",
      "Updating learning rate: 3.911109074562237e-12\n",
      "Updating learning rate: 3.1288872596497897e-12\n",
      "Updating learning rate: 2.503109807719832e-12\n",
      "Updating learning rate: 2.0024878461758655e-12\n",
      "Updating learning rate: 1.6019902769406924e-12\n",
      "Updating learning rate: 1.281592221552554e-12\n",
      "Updating learning rate: 1.0252737772420433e-12\n",
      "Early STOP!!!\n",
      "CPU times: total: 953 ms\n",
      "Wall time: 947 ms\n"
     ]
    }
   ],
   "source": [
    "%time x, history_frac = frac_optimizer(fx, x0,  lr=0.03, alpha=0.9, return_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate: 0.03\n",
      "Updating learning rate: 0.024\n",
      "Updating learning rate: 0.019200000000000002\n",
      "Updating learning rate: 0.015360000000000002\n",
      "Updating learning rate: 0.012288000000000002\n",
      "Updating learning rate: 0.009830400000000003\n",
      "Updating learning rate: 0.007864320000000003\n",
      "Updating learning rate: 0.0062914560000000026\n",
      "Updating learning rate: 0.005033164800000003\n",
      "Updating learning rate: 0.004026531840000003\n",
      "Updating learning rate: 0.0032212254720000023\n",
      "Updating learning rate: 0.002576980377600002\n",
      "Updating learning rate: 0.0020615843020800016\n",
      "Updating learning rate: 0.0016492674416640014\n",
      "Updating learning rate: 0.0013194139533312013\n",
      "Updating learning rate: 0.001055531162664961\n",
      "Updating learning rate: 0.0008444249301319689\n",
      "Updating learning rate: 0.0006755399441055751\n",
      "Updating learning rate: 0.0005404319552844601\n",
      "Updating learning rate: 0.0004323455642275681\n",
      "Updating learning rate: 0.0003458764513820545\n",
      "Updating learning rate: 0.0002767011611056436\n",
      "Updating learning rate: 0.0002213609288845149\n",
      "Updating learning rate: 0.00017708874310761193\n",
      "Updating learning rate: 0.00014167099448608955\n",
      "Updating learning rate: 0.00011333679558887165\n",
      "Updating learning rate: 9.066943647109732e-05\n",
      "Updating learning rate: 7.253554917687786e-05\n",
      "Updating learning rate: 5.802843934150229e-05\n",
      "Updating learning rate: 4.642275147320184e-05\n",
      "Updating learning rate: 3.7138201178561476e-05\n",
      "Updating learning rate: 2.9710560942849182e-05\n",
      "Updating learning rate: 2.376844875427935e-05\n",
      "Updating learning rate: 1.901475900342348e-05\n",
      "Updating learning rate: 1.5211807202738786e-05\n",
      "Updating learning rate: 1.216944576219103e-05\n",
      "Updating learning rate: 9.735556609752823e-06\n",
      "Updating learning rate: 7.788445287802259e-06\n",
      "Updating learning rate: 6.230756230241808e-06\n",
      "Updating learning rate: 4.984604984193447e-06\n",
      "Updating learning rate: 3.987683987354758e-06\n",
      "Updating learning rate: 3.1901471898838066e-06\n",
      "Updating learning rate: 2.5521177519070454e-06\n",
      "Updating learning rate: 2.0416942015256364e-06\n",
      "Updating learning rate: 1.6333553612205092e-06\n",
      "Updating learning rate: 1.3066842889764074e-06\n",
      "Updating learning rate: 1.045347431181126e-06\n",
      "Updating learning rate: 8.362779449449008e-07\n",
      "Updating learning rate: 6.690223559559207e-07\n",
      "Updating learning rate: 5.352178847647365e-07\n",
      "Updating learning rate: 4.2817430781178924e-07\n",
      "Updating learning rate: 3.425394462494314e-07\n",
      "Updating learning rate: 2.7403155699954515e-07\n",
      "Updating learning rate: 2.1922524559963614e-07\n",
      "Updating learning rate: 1.7538019647970893e-07\n",
      "Updating learning rate: 1.4030415718376716e-07\n",
      "Updating learning rate: 1.1224332574701373e-07\n",
      "Updating learning rate: 8.9794660597611e-08\n",
      "Updating learning rate: 7.18357284780888e-08\n",
      "Updating learning rate: 5.746858278247104e-08\n",
      "Updating learning rate: 4.597486622597683e-08\n",
      "Updating learning rate: 3.677989298078147e-08\n",
      "Updating learning rate: 2.9423914384625176e-08\n",
      "Updating learning rate: 2.3539131507700142e-08\n",
      "Updating learning rate: 1.8831305206160116e-08\n",
      "Updating learning rate: 1.5065044164928095e-08\n",
      "Updating learning rate: 1.2052035331942477e-08\n",
      "Updating learning rate: 9.641628265553983e-09\n",
      "Updating learning rate: 7.713302612443187e-09\n",
      "Updating learning rate: 6.1706420899545494e-09\n",
      "Updating learning rate: 4.93651367196364e-09\n",
      "Updating learning rate: 3.949210937570912e-09\n",
      "Updating learning rate: 3.1593687500567297e-09\n",
      "Updating learning rate: 2.527495000045384e-09\n",
      "Updating learning rate: 2.0219960000363072e-09\n",
      "Updating learning rate: 1.617596800029046e-09\n",
      "Updating learning rate: 1.2940774400232369e-09\n",
      "Updating learning rate: 1.0352619520185895e-09\n",
      "Updating learning rate: 8.282095616148717e-10\n",
      "Updating learning rate: 6.625676492918974e-10\n",
      "Updating learning rate: 5.30054119433518e-10\n",
      "Updating learning rate: 4.2404329554681437e-10\n",
      "Updating learning rate: 3.392346364374515e-10\n",
      "Updating learning rate: 2.713877091499612e-10\n",
      "Updating learning rate: 2.1711016731996896e-10\n",
      "Updating learning rate: 1.7368813385597518e-10\n",
      "Updating learning rate: 1.3895050708478016e-10\n",
      "Updating learning rate: 1.1116040566782413e-10\n",
      "Updating learning rate: 8.892832453425931e-11\n",
      "Updating learning rate: 7.114265962740745e-11\n",
      "Updating learning rate: 5.691412770192596e-11\n",
      "Updating learning rate: 4.553130216154077e-11\n",
      "Updating learning rate: 3.642504172923262e-11\n",
      "Updating learning rate: 2.91400333833861e-11\n",
      "Updating learning rate: 2.331202670670888e-11\n",
      "Updating learning rate: 1.8649621365367104e-11\n",
      "Updating learning rate: 1.4919697092293683e-11\n",
      "Updating learning rate: 1.1935757673834948e-11\n",
      "Updating learning rate: 9.548606139067959e-12\n",
      "Updating learning rate: 7.638884911254367e-12\n",
      "Updating learning rate: 6.111107929003494e-12\n",
      "Updating learning rate: 4.888886343202796e-12\n",
      "Updating learning rate: 3.911109074562237e-12\n",
      "Updating learning rate: 3.1288872596497897e-12\n",
      "Updating learning rate: 2.503109807719832e-12\n",
      "Updating learning rate: 2.0024878461758655e-12\n",
      "Updating learning rate: 1.6019902769406924e-12\n",
      "Updating learning rate: 1.281592221552554e-12\n",
      "Updating learning rate: 1.0252737772420433e-12\n",
      "Early STOP!!!\n",
      "CPU times: total: 969 ms\n",
      "Wall time: 974 ms\n"
     ]
    }
   ],
   "source": [
    "%time x, history_multi_frac = multi_frac_optimizer(fx, x0,  lr=0.03, alpha1=1.1, alpha2=0.9, return_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate: 0.03\n",
      "Updating learning rate: 0.024\n",
      "Updating learning rate: 0.019200000000000002\n",
      "Updating learning rate: 0.015360000000000002\n",
      "Updating learning rate: 0.012288000000000002\n",
      "Updating learning rate: 0.009830400000000003\n",
      "Updating learning rate: 0.007864320000000003\n",
      "Updating learning rate: 0.0062914560000000026\n",
      "Updating learning rate: 0.005033164800000003\n",
      "Updating learning rate: 0.004026531840000003\n",
      "Updating learning rate: 0.0032212254720000023\n",
      "Updating learning rate: 0.002576980377600002\n",
      "Updating learning rate: 0.0020615843020800016\n",
      "Updating learning rate: 0.0016492674416640014\n",
      "Updating learning rate: 0.0013194139533312013\n",
      "Updating learning rate: 0.001055531162664961\n",
      "Updating learning rate: 0.0008444249301319689\n",
      "Updating learning rate: 0.0006755399441055751\n",
      "Updating learning rate: 0.0005404319552844601\n",
      "Updating learning rate: 0.0004323455642275681\n",
      "Updating learning rate: 0.0003458764513820545\n",
      "Updating learning rate: 0.0002767011611056436\n",
      "Updating learning rate: 0.0002213609288845149\n",
      "Updating learning rate: 0.00017708874310761193\n",
      "Updating learning rate: 0.00014167099448608955\n",
      "Updating learning rate: 0.00011333679558887165\n",
      "Updating learning rate: 9.066943647109732e-05\n",
      "Updating learning rate: 7.253554917687786e-05\n",
      "Updating learning rate: 5.802843934150229e-05\n",
      "Updating learning rate: 4.642275147320184e-05\n",
      "Updating learning rate: 3.7138201178561476e-05\n",
      "Updating learning rate: 2.9710560942849182e-05\n",
      "Updating learning rate: 2.376844875427935e-05\n",
      "Updating learning rate: 1.901475900342348e-05\n",
      "Updating learning rate: 1.5211807202738786e-05\n",
      "Updating learning rate: 1.216944576219103e-05\n",
      "Updating learning rate: 9.735556609752823e-06\n",
      "Updating learning rate: 7.788445287802259e-06\n",
      "Updating learning rate: 6.230756230241808e-06\n",
      "Updating learning rate: 4.984604984193447e-06\n",
      "Updating learning rate: 3.987683987354758e-06\n",
      "Updating learning rate: 3.1901471898838066e-06\n",
      "Updating learning rate: 2.5521177519070454e-06\n",
      "Updating learning rate: 2.0416942015256364e-06\n",
      "Updating learning rate: 1.6333553612205092e-06\n",
      "Updating learning rate: 1.3066842889764074e-06\n",
      "Updating learning rate: 1.045347431181126e-06\n",
      "Updating learning rate: 8.362779449449008e-07\n",
      "Updating learning rate: 6.690223559559207e-07\n",
      "Updating learning rate: 5.352178847647365e-07\n",
      "Updating learning rate: 4.2817430781178924e-07\n",
      "Updating learning rate: 3.425394462494314e-07\n",
      "Updating learning rate: 2.7403155699954515e-07\n",
      "Updating learning rate: 2.1922524559963614e-07\n",
      "Updating learning rate: 1.7538019647970893e-07\n",
      "Updating learning rate: 1.4030415718376716e-07\n",
      "Updating learning rate: 1.1224332574701373e-07\n",
      "Updating learning rate: 8.9794660597611e-08\n",
      "Updating learning rate: 7.18357284780888e-08\n",
      "Updating learning rate: 5.746858278247104e-08\n",
      "Updating learning rate: 4.597486622597683e-08\n",
      "Updating learning rate: 3.677989298078147e-08\n",
      "Updating learning rate: 2.9423914384625176e-08\n",
      "Updating learning rate: 2.3539131507700142e-08\n",
      "Updating learning rate: 1.8831305206160116e-08\n",
      "Updating learning rate: 1.5065044164928095e-08\n",
      "Updating learning rate: 1.2052035331942477e-08\n",
      "Updating learning rate: 9.641628265553983e-09\n",
      "Updating learning rate: 7.713302612443187e-09\n",
      "Updating learning rate: 6.1706420899545494e-09\n",
      "Updating learning rate: 4.93651367196364e-09\n",
      "Updating learning rate: 3.949210937570912e-09\n",
      "Updating learning rate: 3.1593687500567297e-09\n",
      "Updating learning rate: 2.527495000045384e-09\n",
      "Updating learning rate: 2.0219960000363072e-09\n",
      "Updating learning rate: 1.617596800029046e-09\n",
      "Updating learning rate: 1.2940774400232369e-09\n",
      "Updating learning rate: 1.0352619520185895e-09\n",
      "Updating learning rate: 8.282095616148717e-10\n",
      "Updating learning rate: 6.625676492918974e-10\n",
      "Updating learning rate: 5.30054119433518e-10\n",
      "Updating learning rate: 4.2404329554681437e-10\n",
      "Updating learning rate: 3.392346364374515e-10\n",
      "Updating learning rate: 2.713877091499612e-10\n",
      "Updating learning rate: 2.1711016731996896e-10\n",
      "Updating learning rate: 1.7368813385597518e-10\n",
      "Updating learning rate: 1.3895050708478016e-10\n",
      "Updating learning rate: 1.1116040566782413e-10\n",
      "Updating learning rate: 8.892832453425931e-11\n",
      "Updating learning rate: 7.114265962740745e-11\n",
      "Updating learning rate: 5.691412770192596e-11\n",
      "Updating learning rate: 4.553130216154077e-11\n",
      "Updating learning rate: 3.642504172923262e-11\n",
      "Updating learning rate: 2.91400333833861e-11\n",
      "Updating learning rate: 2.331202670670888e-11\n",
      "Updating learning rate: 1.8649621365367104e-11\n",
      "Updating learning rate: 1.4919697092293683e-11\n",
      "Updating learning rate: 1.1935757673834948e-11\n",
      "Updating learning rate: 9.548606139067959e-12\n",
      "Updating learning rate: 7.638884911254367e-12\n",
      "Updating learning rate: 6.111107929003494e-12\n",
      "Updating learning rate: 4.888886343202796e-12\n",
      "Updating learning rate: 3.911109074562237e-12\n",
      "Updating learning rate: 3.1288872596497897e-12\n",
      "Updating learning rate: 2.503109807719832e-12\n",
      "Updating learning rate: 2.0024878461758655e-12\n",
      "Updating learning rate: 1.6019902769406924e-12\n",
      "Updating learning rate: 1.281592221552554e-12\n",
      "Updating learning rate: 1.0252737772420433e-12\n",
      "Early STOP!!!\n",
      "CPU times: total: 19.2 s\n",
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%time x, history_dist_frac = dist_frac_optimizer(fx, x0,  lr=0.03, alpha1=0.1, alpha2=1.1, return_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_int = list(map(lambda x: fx(x), history_int))\n",
    "fx_frac = list(map(lambda x: fx(x), history_frac))\n",
    "fx_multi_frac = list(map(lambda x: fx(x), history_multi_frac))\n",
    "fx_dist_frac = list(map(lambda x: fx(x), history_dist_frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAI/CAYAAACrl6c+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAB4V0lEQVR4nO3dd3iUVf7+8feZkt5Io5NQRHoNJaIIWEBFLCigFHtv313dXcv+dJvb1LWsuq5dKSqoKFYU7EoxVOlNeg8QSG/P748JLEgCyWQmz5T7dV25Qmae8smOrLfnnOdzjGVZiIiIiIjvOOwuQERERCTUKGCJiIiI+JgCloiIiIiPKWCJiIiI+JgCloiIiIiPKWCJiIiI+JjL7gKOlpqaamVmZtpdhoiIiMhJLViwYK9lWWnVvRdQASszM5OcnBy7yxARERE5KWPMppre0xShiIiIiI8pYImIiIj4mAKWiIiIiI8F1BosERERCXxlZWVs3bqV4uJiu0tpEFFRUbRo0QK3213rcxSwREREpE62bt1KfHw8mZmZGGPsLsevLMsiNzeXrVu30rp161qfpylCERERqZPi4mJSUlJCPlwBGGNISUmp82idApaIiIjUWTiEq8O8+V0VsERERCTonHbaaSc95oknnqCwsLABqjmeApaIiIgEnR9++OGkxyhgiYiIiNRBXFwcAF999RWDBg3isssuo0OHDowdOxbLsnjqqafYvn07gwcPZvDgwQ1en54iFBERkaC2aNEili9fTrNmzRgwYADff/89d955J//617/48ssvSU1NbfCaFLBERETEa3/8YDkrth/06TU7NUvgoQs71/r4vn370qJFCwB69OjBxo0bOf30031aU11pilBERESCWmRk5JE/O51OysvLbazGQyNYIiIi4rW6jDQ1tPj4eA4dOmTLFKFGsERERCQk3XjjjQwbNsyWRe7GsqwGv2lNsrKyrJycHLvLEBERkRNYuXIlHTt2tLuMBlXd72yMWWBZVlZ1x2sES0RERMTHFLBEREREfEwBS0RERMTHFLBEREREfEwBS0RERMTHwi5glRQcoLIycJ6cFBERkdATVgFr6fcfMOecbKb/9Vq7SxEREZF6eOqpp+jYsSNjx461u5RqhVXAOqX7GZS5odXbc9m18nu7yxEREREvPfvss3z++edMnjz5yGuBsEXOYWEVsKLjktgy4WbcFbD4/26iMoA+CBEREamdm2++mQ0bNnDeeeeRmJjI+PHjGTBgAOPHj2fjxo2cccYZ9OrVi169evHDDz8cOe8f//gHXbt2pXv37tx7771+rTHs9iK8eMwtvDrnPc77bidf/nE0Z/35HbtLEhERkTp47rnn+PTTT/nyyy95+umn+eCDD/juu++Ijo6msLCQzz//nKioKNauXcsVV1xBTk4On3zyCe+//z7z5s0jJiaGffv2+bXGsAtYybERbDvrEdZsuYqM6SvYdMH7ZPS/yO6yREREgtMn98LOn3x7zSZd4by/1/rwESNGEB0dDUBZWRm33347ixcvxul0smbNGgBmzZrFNddcQ0xMDADJycm+rfkXwmqK8LAJp7fjuS7jKHPB2gfup6K0xO6SRERExEuxsbFH/vz444/TuHFjlixZQk5ODqWlpbbUFHYjWADdWyYR0WYg3xV/y7DZP/Pl/SM5+9EP7S5LREQk+NRhpKkh5OXl0aJFCxwOB6+99hoVFRUAnHPOOfzpT39i7NixR6YI/TmKFZYjWAAT+mfwZNzNrGnvJP2T9Wz8dqrdJYmIiEg93Xrrrbz22mt0796dVatWHRndGjZsGCNGjCArK4sePXrw6KOP+rUOY1n+a7ppjGkJvA40Bizgecuynqzp+KysLCsnJ8dv9RytuKyC0/7+Bec02sSlLz9GQYKDMz/NwRkV3SD3FxERCVYrV66kY8eOdpfRoKr7nY0xCyzLyqrueH+PYJUDd1uW1QnoD9xmjOnk53vWSpTbyaislkzb1pS9o3vTdGclX953id1liYiISAjwa8CyLGuHZVkLq/58CFgJNPfnPetibL9WACzvdj9rOrppPHMTG76cYnNVIiIiEuwabA2WMSYT6AnMa6h7nkzL5BiGdGjMWznb6Pm3ZymIgo1/+AvlRQV2lyYiIiJBrEECljEmDngH+D/Lsg7+4r0bjTE5xpicPXv2NEQ5x5iQnUFuQSkLi1pTOD6bprssvrjv0gavQ0REREKH3wOWMcaNJ1xNtizr3V++b1nW85ZlZVmWlZWWlubvco5zertUWqfG8tqcjQy+60XWdoqg6WebWTf71QavRUREREKDXwOWMcYALwErLcv6lz/v5S2HwzC+fwaLNh9g+Y5D9P/HCxRFwsY//5Pygjy7yxMREZEg5O8RrAHAeGCIMWZx1df5fr5nnY3s3YJot5PX52wk/ZS+FF01kOY7LWbdf7HdpYmIiIgfxMXFAbBx40amTPnfA245OTnceeed9b6+v58i/M6yLGNZVjfLsnpUfX3sz3t6IzHazcU9m/P+4u0cKCzljDv/w88dImk6ayfrPn3a7vJERETET34ZsLKysnjqqafqfd2w7eT+SxOyMygpr2RqzhYcDge9H3uFMhesf+QZyg7tsrs8EREROcrGjRvp0KEDV199Ne3bt2fs2LHMmjWLAQMGcMoppzB//nz+8Ic/HNOxvUuXLmzcuPGY69x77718++239OjRg8cff5yvvvqK4cOH17s+BawqHZsm0DczmUlzN1NZadG4bU+KrjqbVttg5oN6qlBERCTQrFu3jrvvvptVq1axatUqpkyZwnfffcejjz7KX//611pd4+9//ztnnHEGixcv5le/+pXPagvLzZ5rMj47gzveWMTXa/YwuEM6p//qKWbN7k2z2ftY8/HfaX/+vXaXKCIiElD+Mf8frNq3yqfX7JDcgd/1/d1Jj2vdujVdu3YFoHPnzpx11lkYY+jatSsbN26kR48ePq2rLjSCdZShnZuQFh/J63M2AmCMoccTr+CwYOW/X6M0d4O9BYqIiMgRkZGRR/7scDiO/OxwOCgvL8flclFZWXnkmOLi4garTSNYR4lwObiibyv+/cVaNuUWkJESS9op3Vk37hzav/I5H/59NJf+Yy44nHaXKiIiEhBqM9Jkl8zMTD788EMAFi5cyM8//3zcMfHx8Rw6dMjn99YI1i+M7dcKpzFMmrvpyGv973mc3S2jaT4rn1UzNE0oIiISDEaOHMm+ffvo3LkzTz/9NO3btz/umG7duuF0OunevTuPP/64z+5tLMvy2cXqKysry8rJybG7DG6bvJDv1u1l7n1nER3hGa3a/VMOu0ePZ2kHi8sffwV3RrbNVYqIiNhj5cqVdOzY0e4yGlR1v7MxZoFlWVnVHa8RrGqMz84gr6iMD5ZsP/JaetcsCi8bQs8Vhneeux6K1eVdREREqqeAVY1+rZNp3ziO1+Zs5OgRvqwH/kVeWjRNvqxk5bTrIYBG/0RERCRwKGBVwxjDhOxMlm8/yMLNB4687oiMpM3fHqXxAfjms58oW/CqXSWKiIhIAFPAqsElPZsTH+liYlXLhsPSTx9C4dBsBuQYJn/wMOxZbU+BIiIiErAUsGoQG+liZO8WfPzTTvYcKjnmvR5//BdlsREkf+tm+bQJUNZwfTVEREQk8ClgncC4/hmUVlTy1o+bj3ndmZREk/vu45Tt8MHyA5R+9oBNFYqIiEggUsA6gXbpcZzeLpXJ8zZTXlF5zHtNLh1Nac8OnPOdg5eXvA0rP7SpShERkfB2eFPnBx98kFmzZtV43HvvvceKFSsapCYFrJMYn53BjrxiZq3cfczrxhg6/u1xIiscuH6MZdlHd8C+4zvEioiISMP405/+xNlnn13j+wpYAeSsDuk0S4xi4tyNx70XkZlJ0g3XMWClxasHoiiZdhWUlxx/EREREfGphx9+mPbt23P66aezerXngbOrr76at99+G4B7772XTp060a1bN+655x5++OEHZsyYwW9+8xt69OjB+vXr/Vqf9iI8CZfTwdj+GTwyczXrdh+iXXr8Me83u/k2VsyYwQWzdvHc5Ru5a+b9cMFjNlUrIiIS+hYsWMCbb77J4sWLKS8vp1evXvTu3fvI+7m5uUyfPp1Vq1ZhjOHAgQMkJSUxYsQIhg8fzmWXXeb3GhWwamF0n5Y8OWstE+ds4o8XdTnmPUdkJK3//Fec117HdyviWFL6Ot1bZUNX/394IiIidtv5179SsnKVT68Z2bEDTe6/v8b3v/32Wy655BJiYmIAGDFixDHvJyYmEhUVxXXXXcfw4cMZPny4T+urDU0R1kJqXCQXdGvKOwu3kV9Sftz7saedRsx5Q7l4rsUTkU0p/uAu2LvWhkpFRETE5XIxf/58LrvsMj788EOGDRvW8DU0+B2D1PjsDKYv2sb0RdsY3z/juPeb3Xc/Bd98w7mfF/PM8DjunjoBrp8NETE2VCsiItIwTjTS5C8DBw7k6quv5r777qO8vJwPPviAm2666cj7+fn5FBYWcv755zNgwADatGkDQHx8PIcOHWqQGjWCVUs9WybRpXkCr/9w7P6Eh7nT02ly16/o8bPFqq1uFueth49/Y0OlIiIioa1Xr16MHj2a7t27c95559GnT59j3j906BDDhw+nW7dunH766fzrX/8CYMyYMTzyyCP07NnT74vcTXVhwS5ZWVlWTk6O3WXUaOqPW/jtO0t544b+ZLdNOe59q7yc9ZeNZM/29TxySxyTN68iesTT0HOcDdWKiIj4x8qVK+nYsaPdZTSo6n5nY8wCy7KyqjteI1h1MKJHM5Ji3NW2bAAwLhfNHvoDSQcr6Pv1QZ7K6AQf3QO7ljdsoSIiImIrBaw6iHI7GZXVkpnLd7Ezr/r9B2N69iRx5KVc+CN8lXuIBfGJ8NZ4KM5r4GpFRETELgpYdTSuXwaVlsWU+ZtrPCb97rtxxcRx8xcu/l/jZhTmbYZ3b4LKyhrPERERkdChgFVHrVJiGNQ+jSnzNlNaXn1gciUnk/Z/d9F+fTHNF+/mye5DYc0n8M0jDVytiIiIfwTSGm5/8+Z3VcDywoTTMtmbX8Kny3fWeEyjMWOI7NiRm7+J4p1dS/ix03nw1d9gzcwGrFRERMT3oqKiyM3NDYuQZVkWubm5REVF1ek8PUXohcpKi8GPfUV6fCTTbj6txuMKFy5k05VjmTUokY/OTuTdvfnE7N8CN34JKW0bsGIRERHfKSsrY+vWrRQXV78eOdRERUXRokUL3G73Ma+f6ClCNRr1gsNhGNcvg4c/XsmK7Qfp1Cyh2uNievUiYcSFnPXJJ8zoUMC/el7A7+e+CW+Ng+tnQURsA1cuIiJSf263m9atW9tdRkDTFKGXLs9qQaTLUWPLhsPS774HpzuC++c15a2NHzHv7Hthzyp4/3YIoNFDERER8R0FLC8lxURwcY/mvLdoO3lFZTUe526cTuqtt9Bk0RbO3ZHGgz9Pp2DwfbD8XZjzdANWLCIiIg1FAasexmdnUFRWwdsLtp7wuEYTJhCRkcG1Xxh2H9zOY+5i6DgCPn8QNnzdQNWKiIhIQ1HAqocuzRPp1SqJSXM3UVlZ83SfIyKC9PvuxbF5O7/f2otpa6bxQ7+rILU9vH0NHKi5p5aIiIgEHwWsepqQncnPewv4dt3eEx4XP2gQsQPPoPOMFXR2tOAPOf+kYOSLUFEOb1wBJfkNVLGIiIj4mwJWPZ3XtQmpcRFMnLPxpMc2vvderOJifr+0DTsLdvKvn9+Dy1+B3Stgujq9i4iIhAoFrHqKdDkZ06cVs1ftZsu+whMf26YNyWOvxPnhl9waex5T10xlfmw8nPswrPrQ04hUREREgp4Clg9c2a8VBpg87+RrqVJvvRVnUhLnvreNVnEteeiHhyjsfRX0HAff/BOWvev/gkVERMSvFLB8oFlSNOd0asxbP26muKzihMc6ExNJu/MOSnIW8JeKC9mav5WnFv8bLvgXtOwP790K2xc3TOEiIiLiFwpYPnJVdib7C8v4cOmOkx6bdPnlRJ5yCvHPv8vYtqOYsnIKC3OXw+hJEJsKb14Jh3Y1QNUiIiLiDwpYPpLdNoV26XG1WuxuXC7S7/0dZVu3ctWKNJrFNePBHx6kKCoOxkyBov3w1lgoC489nkREREKNApaPGGMY3z+DJVvzWLzlwEmPjxswgLgzz+Tg8y/xx06/ZtPBTTy7+Flo2g0u+S9s/RE+/D9tpyMiIhKEFLB86NJezYmNcPJ6LUaxANJ/91sqi4rImDaXy9pfxusrXmfpnqXQaQQMuh+WvAHfP+HXmkVERMT3FLB8KD7KzaW9WvDh0h3sKyg96fGRbdrQaMwY9r81lTuTLiE9Jp3/9/3/o6SiBM78LXS+FGb9AVa87//iRURExGcUsHxsfHYGpeWVvPXjllodn3r7bThiYsh/4lkeyn6IDXkbeG7Jc2AMXPwfaNEX3r0Rtub4uXIRERHxFQUsH2vfOJ7+bZKZNHcTFSfYn/AwV6NGpN58E/lff03PzU4uansRryx7heW5y8EdBVe8AfFN4I0xsH9TA/wGIiIiUl8KWH4wITuTbQeK+GLV7lod32jcONzNm7Prn49wT++7SY5K5v99//8oqyjztG24chpUlMKUUVB0wL/Fi4iISL0pYPnBOZ0a0yQhqtaL3R2RkaT96leUrFwJM7/mwewHWbt/LS/89ILngLT2nh5Zuetg2lVQUea/4kVERKTeFLD8wO10cGW/Vny7di8b9uTX6pyE888jqksX9jzxJAPT+nNBmwt4YekLrN632nNA64Fw4VOw4Sv46Ndq3yAiIhLAFLD8ZEzflridhklzT74/IYBxOEj/zW8o37mTfRMncm+fe0mITPBMFVZWjVj1HAtn3AMLX4fvn/Rj9SIiIlIfClh+kh4fxbAuTZm2YAuFpeW1Oie2X1/iBg0i97/PE1dk8fv+v2flvpW8suyV/x00+IGq9g0PwfL3/FO8iIiI1IsClh9dlZ3BoeJy3lu0vdbnpN9zN5WFheQ+9xznZJzDuRnn8tyS51i3f53nAIfD076hZT+YfhNsnuun6kVERMRbClh+1DujER2bJvD6nI1YtVwzFdmuHYmXXsK+KW9QunUr9/e7nzh3HA/+8CDllVUjYe4oGPMGJDSHKaNhzxo//hYiIiJSVwpYfmSMYUJ2Bqt2HiJn0/5an5d2xx0Yh4M9Tz5FSnQK9/W7j5/2/sTEFRP/d1BsCox7B5xumDQSDu30w28gIiIi3lDA8rOLejQjPsrFaz9srPU57saNSZ4wgYMffEDxihUMyxzGkJZDeHrR0/yc9/P/DkxuDWOnQWEuTL4Mig/6/hcQERGROlPA8rOYCBeX927Jp8t2svtgca3PS7nhepyJiez+1+MYY/h9/98T5Yriwe8fpKKy4n8HNusJo16HXStg6ngoP/keiCIiIuJffg9YxphhxpjVxph1xph7/X2/QDQ+O4PySos35tduf0IAZ0ICKTfeSMF331Ewdx5pMWn8ru/vWLxnMW+seuPYg085G0b829Mja8bt6pElIiJiM78GLGOME3gGOA/oBFxhjOnkz3sGotapsQxsn8aU+Zsoq6is9XmNxo3F1aQJu//1LyzL4sI2F3JG8zN4cuGTbDn4i7DWcywM/j0sfQtm/9HHv4GIiIjUhb9HsPoC6yzL2mBZVinwJnCRn+8ZkCb0z2DXwRI+W76r1uc4IiNJu+N2ipcu5dCsWRhjeDD7QVwOFw/NeYhK6xdhbeA90Psa+O5xmP+Cj38DERERqS1/B6zmwNFDLVurXgs7gzuk0zwputb7Ex6WeNFFRLRpw54nnsSqqKBJbBPuzrqbH3f+yLtr3z32YGPg/Efh1PPh49+oEamIiIhNbF/kboy50RiTY4zJ2bNnj93l+I3TYRifncG8n/exeuehWp9nXC7S7rqL0vXryZvxAQAjTxlJ3yZ9eSznMXYV/GJEzOmCkS9By77wzvWw/gtf/hoiIiJSC/4OWNuAlkf93KLqtSMsy3resqwsy7Ky0tLS/FyOvUZltSTC5WDi3I11Oi/+3HOI6tyZvf/+N5WlpRhjeCj7Icoqy/jLvL8c38Q0IgaufAtS28Ob42Brju9+CRERETkpfwesH4FTjDGtjTERwBhghp/vGbCSYyO4sFsz3l24jYPFZbU+zxhD2q9+Rdn27RyYOg2AVgmtuL3H7Xy15Stmbpp5/EnRjWD8uxCX5umRtXulj34LERERORm/BizLssqB24GZwEpgqmVZy/15z0A3ITuDwtIK3l2wtU7nxQ44jZg+fdj73+eoLCoCYFyncXRK6cTf5v2NA8UHjj8pvgmMfw+cETDxEti/qf6/gIiIiJyU39dgWZb1sWVZ7S3LamtZ1sP+vl+g694yie4tk5g4d1Ot9yeEw6NY/0fFnr3snzwZAJfDxZ9O+xMHSw7ySM4j1Z+Y3BrGT4eyQk/Iyt/ti19DRERETsD2Re7haEL/DNbvKeCH9bl1Oi+mVy9iB55B7gsvUpGfD8CpyadyTZdrmLF+Bt9v+776Ext3hiunwcHtMOlSKM6r768gIiIiJ6CAZYMLujUlOTaiTvsTHpZ2511U5OWx79XXjrx2U/ebaJ3Ymj/O+SOFZYXVn9iqH4ye5FmL9cYVUFbkZfUiIiJyMgpYNohyOxmV1ZJZK3ex7UDdgk50l87En3M2+159lYoDBwCIdEbyx9P+yM6CnTy16KmaTz7lbLjkv7DpB5h2DVTUfqG9iIiI1J4Clk3G9msFwJR5dV94nnr7HVQWFJD7yqtHXuuZ3pMxHcYwZeUUFu9eXPPJXS+DCx6FNZ/A+7dDZe237hEREZHaUcCyScvkGIZ0aMyb87dQUl5Rp3OjTm1PwnnD2DdxIuX79h15/a5ed9E4tjEP/fAQpRWlNV+gz/VV+xa+CR/9WptDi4iI+JgClo0mZGeQW1DKxz/tqPO5qbffjlVcTO5LLx15LdYdy4P9H2RD3gaeX/r8iS8w8B44/Vew4BWYeb9CloiIiA8pYNno9HaptE6N5fU5dZ8mjGzThoThF7B/8hTK9+498voZLc7gwjYX8tJPL7F63+qaL2AMnPUQ9LsZ5j4LX/zZm19BREREqqGAZSOHwzC+fwaLNh9g2ba6t05Iu/VWrNJScl986ZjXf9vntyREJvCHH/5AReUJph+NgWF/h15XwbePwTc19NISERGROlHAstnI3i2Idjt5fc7GOp8bkZlJ4oUXsv+NNyjb/b8GoklRSdzX9z6W5S5j0spJJ76IMTD8Ceg2Br74C/zwdJ3rEBERkWMpYNksMdrNxT2b8/7i7RwoPMHC9Bqk3noLVnk5+156+ZjXh2YOZVCLQTy96Gm2HNxy4os4HHDRM9DpIvjsAZj/Qp3rEBERkf9RwAoAE7IzKCmvZGrOSYJQNSIyMjyjWG++SfmePUdeN8bwQP8HcDlc/HHOH0++LY/TBZe+CO3Pg4/vgUWT61yLiIiIeChgBYCOTRPom5nMpLmbqays+9N8qbfcjFVeTu4vRrGaxDbhV71/xbyd85i+bvrJL+SKgMtfhTaDYcbt8NPbda5FREREFLACxvjsDDbvK+TrNXtOfvAvRGRkkDh8uGcU66gnCgEua38ZWY2zePTHR9ldWIuNnt1RMGYKtMqGd2+ElR/UuR4REZFwp4AVIIZ2bkJafKRXi90BUm6+yfNE4cuvHPO6wzj4w2l/oLSylL/O+2vtLhYRA1e+Bc17wbSrYeWHXtUkIiISrhSwAkSEy8EVfVvx1Zo9bMotqPP5ka1bk3DBBex/441jursDZCRkcGuPW5m9eTazNs2q5QXjYdw70LQHTLtKIUtERKQOFLACyNh+rXAaw6S5dW88CpB6801YxcXse/W1496b0GkCHZI78Nd5f+VQ6aHaXTAqEca/q5AlIiJSRwpYAaRxQhRDOzdhas5Wikrrtj8hQGTbtsQPG8r+yZOpOHDgmPdcDhd/yP4DucW5PLnwydpf9Jcha9VHda5LREQk3ChgBZjx2RnkFZXxwZLtXp2fevMtVBYUsG/S8W0WOqd25soOVzJ19VQW715c+4seHbKmTlDIEhEROQkFrADTr3Uy7RvH8dqcjSfvXVWNqFPbE3fWWeybOJGK/Pzj3r+j5x00iW3CH+f8kbKKsjpc+HDI6q6QJSIichIKWAHGGMP47EyWbz/Iws0HvLpG6s03UZmXx/433jjuvRh3DL/v/3vWHVjHK8tfqebsE4hKhPHTq0KWpgtFRERqooAVgC7t2Zz4SBcTvWzZEN21K7EDBrDv1deoLC4+7v2BLQYyNHMo/13yXzbm1fEeR0JWN4UsERGRGihgBaDYSBcje7fg4592sudQiVfXSL35Jipyczkwrfpu7Pf2vZdIZyR/mvunuk9F/jJkrZjhVY0iIiKhSgErQI3rn0FpRSVv/bjZq/Nj+vQhundvcl9+Gav0+E2kU6NT+XXWr/lx54+8t+69ut/gcMhq1tPTjFTb6oiIiByhgBWg2qXHMaBdCpPnbaa8otKra6TeeAPlO3aQ90H1/asuPeVSeqX34tGcR8ktyq37DQ4vfG+VDe9cD4smeVWniIhIqFHACmATsjPZkVfMrJW12EOwGrEDBxLZoQO5L7yAVXF8Xy2HcfBQ9kMUlRfxzx//6V2RkfEwdhq0HQzv3wbzX/DuOiIiIiFEASuAndUhnWaJUUycu9Gr840xpN54A6UbN3Jo1uxqj2mT1Ibru17Pxz9/zHfbvvOu0IgYGPMGtD8PPr4Hfnjau+uIiIiECAWsAOZyOhjbP4Pv1+Wybnctt7f5hfhzz8XdqpVnFKuGxezXd72ezIRM/jL3LxSWFXpXrDsKRr0OnS6Czx6Abx7x7joiIiIhQAErwI3u05IIp4OJc7zbn9C4XKRcdx3Fy5ZROHdutcdEOCN4KPshtuVv4z9L/uN9sa4IGPkydBsNX/wFZv8ZvGiWKiIiEuwUsAJcalwkF3RryjsLt5FfUu7VNRIvvghnWiq5L7xY4zFZTbIYecpIJq6YyMrcld6WC04XXPwc9JoA3z4Kn/1eIUtERMKOAlYQGJ+dQX5JOdMXbfPqfEdkJMkTJlDwww8ULVte43G/6v0rkiKT+MOcP1BRWffNpv93QwcMfxL63ghznoaP7oZK756EFBERCUYKWEGgZ8skujRP4PUfvNufEKDRmDE44uLY9/JLNR6TGJnIvf3uZUXuCqasmuJtuR4OB5z3TxhwF+S8BNNvhLrsfSgiIhLEFLCCgDGGCf0zWbs7n7kb9nl1DWd8PI3GjObgpzMp3bKlxuOGZgxlYIuB/HvRv9mev93bkj2MgXP+BGc9BD9NgzfHQqmXi+hFRESCiAJWkBjRoxlJMW6vWzYANBo/AZxO9r1S8ybPxhge6PcAAH+b/zev73WMM34Nwx+HtZ/BpJFQnOeb64qIiAQoBawgEeV2MiqrJTOX72Jn3vEbONeGu3E6iRdeyIF3p1O+f3+NxzWLa8at3W/lqy1f8cXmL7ys+BeyroXLXoKt8+HV4ZC/xzfXFRERCUAKWEFkXL8MKi2LKfO8a9kAkHLtNVjFxeyffOI1VmM7jeWURqfwt/l/87431i91GQlXvAl718Irw+BAzVOVIiIiwUwBK4i0SolhUPs0pszfQmm5d0/lRbZrR9ygQeyfPJnK4ppHwtwONw/2f5CdBTvr1xvrl045x7NJdP4eeHmYJ2yJiIiEGAWsIDPhtEz25pfw6fKdXl8j+dprqNi/n7z33j/hcT3SexzpjbV632qv73ecjGy4+kMoL4aXh8L2xb67toiISABQwAoyZ56SRkZKDBPnbPT6GjF9+hDVpQv7XnkF6yT9qX7V+1ckRCTwp7l/otLyYS+rpt3g2pngjoHXLoSNXu6DKCIiEoAUsIKMw2EY1y+DHzfuZ8X2g15dwxhD8jVXU7ppE/lffXXCYxMjE7mnzz0s3bOUd9a+49X9apTaDq79FOKbwsRLYPl7vr2+iIiITRSwgtDlWS2IdDnq1bIhYehQXM2asu/lmls2HHZhmwvJapzF4wseJ7co1+t7ViuxhSdkNesJ066Gec/79voiIiI2UMAKQkkxEVzcoznvLdpOXpF33dGNy0Xy+AkU5uRQ9NOyEx9rDP+v//+jqLyIx3Ie8+p+JxSTDBPeh1PPg09+A7P/pP0LRUQkqClgBanx2RkUlVXw9oKtXl8j6fLLcMTGsu+11056bJukNlzT+Ro+2PAB83fM9/qeNXJHw6iJ0Ptq+PYxeP82ba0jIiJBSwErSHVpnkivVklMnLORykrvRnuccXEkXXYZBz/9lLKdJ38q8cZuN9IirgV/nvtnSitKvbrniQtywfAnYNB9sHgyvHkllBb4/j4iIiJ+poAVxCZkZ7Ixt5Bv1+31+hqNxo+Hykr2T5580mOjXFE80P8BNh7cyCvLTr52yyvGwKB7PUFr3SzPE4YFPl73JSIi4mcKWEHsvK5NSI2LqFfLhogWzYk/+2z2T51GZeHJO7af3vx0hmYO5fmlz7P54Gav73tSWdfA6Emwazm8fC7s3+i/e4mIiPiYAlYQi3Q5GdOnFbNX7WbLPu+3s0m+agKVeXnkvX/ixqOH/bbPb3E73Tw872Esfy5G73CBZ/F7wV546VzYsdR/9xIREfEhBawgd2W/VhhgUj32J4zu1cvTeHTipJM2HgVIj0nnjp538MP2H5i5aabX962VVv09DUkdbnjlfFjvo82nRURE/EgBK8g1S4rmnE6NmfrjForLKry6hjGG5AnjKd2wgYLvf6jVOWNOHUOnlE78c/4/OVR6yKv71lp6B7juM0hqBZMvh4Wv+/d+IiIi9aSAFQKuys5kf2EZHy7d4fU1EoYNw5mWyr6JtQsvToeTB/s/yN6ivTy96Gmv71tric09DUlbD4QZd8DsP6tXloiIBCwFrBCQ3TaFdulx9VrsbiIiaHTFFRR88y0lP/9cq3M6p3ZmTIcxvLHqDZbvXe71vWstKgGunAq9JsC3j8I710N5if/vKyIiUkcKWCHAGMP4/hks2ZrH4i0HvL5Oo1GjMG43+yedvGXDYXf0vIOU6BT+Mvcvvt0MuiZON1z4FJz1ECx7G16/GAr3+f++IiIidaCAFSIu7dWc2Agnr9djFMuVmkrC+eeRN306FYdqt64qPiKeX/f+Nctyl/Hu2ne9vnedGANn/Bouexm2LYAXz4bc9Q1zbxERkVpQwAoR8VFuLunVnA+X7mBfgfdd1huNG0dlYSF509+r9TnD2wynV3ovnlj4BAeKD3h97zrrMtLTxqFoH7x0Dmye13D3FhEROQEFrBAyITuT0vJK3vpxi9fXiO7alaju3dg/eXKtWjaAZ4rygf4PkF+az5OLnvT63l7JyIbrZ0NUoqfr+/LpDXt/ERGRaihghZD2jePp3yaZSXM3UeHl/oQAyePGUbppEwXff1/7ezdqz5Udr+SdNe+wbO8yr+/tlZS2cN0saNYDpl0N3z2hJwxFRMRWfgtYxphHjDGrjDFLjTHTjTFJ/rqX/M+E7Ey2HSjii1W7vb5GwtChOFNT2T95Sp3Ou7X7rUcWvFdUeteTy2uxKTBhBnS+FGY9BDNuh3I/bEgtIiJSC/4cwfoc6GJZVjdgDXCfH+8lVc7p1JjGCZH1WuxuIiJoNOpy8r/+mtIttZ9ujIuI456se1ieu5x31zXQgvejuaNg5Esw8LewaBJMvFgbRYuIiC38FrAsy/rMsqzyqh/nAi38dS/5H7fTwdh+GXy7di8b9uR7fZ2k0aPB4WD/G2/W6bzzW59PVuMsnlz4JPuL93t9f685HDDkAbj0RdiaAy8Mht2rGr4OEREJaw21Buta4JMGulfYG9O3JW6nYdLczV5fw924MfFnnUXeO+9QWVxc6/OMMdzf737PgveFDbzg/WjdLodrPoayIs8Thms/t68WEREJO/UKWMaYWcaYZdV8XXTUMQ8A5UC13SuNMTcaY3KMMTl79uypTzlSJT0+imFdmjJtwRYKS8tPfkINGl15JRV5eRz85NM6nXdKo1MY23Es7659l6V7lnp9/3prkQU3fgmNMmDKKJjzrBa/i4hIg6hXwLIs62zLsrpU8/U+gDHmamA4MNayqv83m2VZz1uWlWVZVlZaWlp9ypGjTMjO4FBxOe8t2u71NWL69SWibVv2T6nbYneAW7rfQmp0Kg/Pe7jhF7wfLbEFXDsTTj0fZt4HH9ylxe8iIuJ3/nyKcBjwW2CEZVmF/rqPVC8roxEdmybw+pyN1JBtT8oYQ6MxYyj+6SeKltVtr8HDC95X5K7gnbXveHV/n4mIhVET4Yy7YeFrMOlSba8jIiJ+5c81WE8D8cDnxpjFxpjn/Hgv+QVjDBOyM1i18xA5m7xfbJ548UWY6Gj2v/lGnc89r/V59i54P5rDAWc9CJc8D1vmwQtDYM8ae2sSEZGQ5c+nCNtZltXSsqweVV83++teUr2LejQjPsrFaz9s9Poazvh4EocP5+CHH1Fx8GCdzjXG8EC/BygoK7B3wfvRuo+Gqz+C0nx48SxY85ndFYmISAhSJ/cQFhPh4vLeLfl02U52H6z9k4C/lDRmNFZxMXnvz6jzue0atWNcx3G8s/YdluxZ4nUNPtWyL9zwJTTK9Cx+//YxLX4XERGfUsAKceOzMyivtHhjfj32J+zcmahu3dj/5pteree6pcctpEen8/Bcmxe8Hy2ppWfxe5eRMPtPMO0qKPG+b5iIiMjRFLBCXOvUWAa2T2PK/E2UVdRu8+bqNBo9mtL16ynKyanzubHuWO7pcw8r9620f8H70SJiYOSLcM6fYeUH8NK5sH+j3VWJiEgIUMAKAxP6Z7DrYAmfLd/l9TUSzj8PR3w8+6dO8+r8YZnD6N24N/9e9G/ySvK8rsPnjIEBd8LYaXBwKzw/CDZ8ZXdVIiIS5BSwwsDgDuk0T4qu1/6EjuhoEkeM4NDMmZTvr/sTgcYY7ut7HwdLD/Ls4me9rsNv2p3tWZcV1wQmXqqmpCIiUi8KWGHA6TCMz85g3s/7WL3zkNfXSRo9Cqu0lLz33vfq/FOTT+Xy9pfz1uq3WLM/AFskpLSF6z+HU8/zNCV97xbPVjsiIiJ1pIAVJkZltSTC5WDi3I1eXyOqfXuie/TgwLRpXjcvvb3H7cS6Y/nH/H94fQ2/ioz3NCUd/AAseQNeOQ/yttpdlYiIBBkFrDCRHBvBhd2a8e7CbRwsLvP6OkmjRlG6YQNFCxZ4d35UEnf0vIP5O+cza/Msr+vwK4cDzvwtjHkD9q7zrMv6+Ru7qxIRkSCigBVGJmRnUFhawbsLvB+RSThvmGex+1tTvb7GZe0vo32j9jzy4yMUlQfwFFyH8+GGLyC6Ebx+EXz3hNZliYhIrShghZHuLZPo3jKJiXM3eT0954iOJvHC4Rz67DMq8rx7GtDlcHFv33vZUbCDV5e96tU1Gkxae0/I6jgCZj0EU8dDcd062ouISPhRwAozE/pnsH5PAT+sz/X6GkmXX45VUkLeBx96fY0+TfowNHMoLy17ie35272+ToOIjIfLX4VzH4ZVH8MLg2H3SrurEhGRAKaAFWYu6NaU5NiIeu1PGNWxI1GdO9drsTvA3b3vxmB4LOcxr6/RYIyB026Hqz7wjGC9MAR+etvuqkREJEApYIWZKLeTUVktmbVyF9sOeL/+KenyyyhZvZriZcu9vkbTuKZc1/U6Ptv0GfN3zPf6Og0qcwDc9A006QbvXAef3gcV3j80ICIioUkBKwyN7dcKgCnzNnl9jYQLLsBERXHgnfqN4lzd+WqaxzXnb/P/Rnlleb2u1WASmsLVH0K/W2Dus/DahXBop91ViYhIAFHACkMtk2MY0qExb87fQkm5d5svO+PjSRg6lIMffkRlYaHXtUS5ovhN1m9Yd2Ad09Z4tw2PLZxuOO/vMPIl2LEEnjsDNn5vd1UiIhIgFLDC1ITsDHILSvn4px1eXyPpspFU5udz6PPP61XLkFZD6Ne0H08vepr9xXXfhsdWXS/zPGUYleAZyfrhabVyEBERBaxwdXq7VFqnxvL6HO+nCaOzsnBntOLAO+/WqxZjDPf2uZeCsgKeXvR0va5li/SOnn0MO5wPnz0Ab46FoiALiiIi4lMKWGHK4TCM75/Bos0HWLbNu35WxhiSLh1J4fz5lG7eXK962jVqx5gOY3h77duBuU/hyUQleLbYGfo3WDsTnhsIW73rdi8iIsFPASuMjezdgmi3k9fnbPT6GokXXwQOBwemT693Pbd0v4U4dxz//PGfgblP4ckYA9m3wrUzAQteHgpz/6MpQxGRMKSAFcYSo91c3LM57y/ezv6CUq+u4W7cmNgBA8h7732sCu8WzB+pJzKRW3vcyrwd8/h669f1upatWmR5Wjmccg58ei+8NQ6KDthdlYiINCAFrDA3ITuDkvJKpi3Y4vU1ki69hPIdOyiYO7fe9Yw6dRStE1vzWM5jlAVzf6mYZBgzxdP9fc2n8N+BsG2h3VWJiEgDUcAKcx2bJtAnsxGT5m6mstK7qay4IUNwJCSQ9279pwndDjf3ZN3DxoMbeXP1m/W+nq0Od3+/5hOorICXzoV5/9WUoYhIGFDAEiZkZ7J5XyFfr9nj1fmOyEgSLjifQ7NmUXHoUL3rOaP5GZzW7DT+s+Q/HCg+UO/r2a5lX7j5W2g7BD75LUydAMXePVggIiLBQQFLGNq5CWnxkbxWj8XuSZdcglVSwsFPP613PcYYfpP1GwrKCnh2ybP1vl5AiEmGK96Ec/4Eqz7yTBluX2R3VSIi4icKWEKEy8EVfVvx9Zo9bMot8OoaUV27EtGmDXnT3/NJTe0atePy9pczdfVUNhzY4JNr2s7hgAF3eaYMK8o8U4ZzntWUoYhICFLAEgCu7NsKhzFMmutd41FjDImXXEzRwoWUbvK+eenRbu1xKzGuGB7JecQn1wsYrfrBTd9C27Ng5n0wZRQU7LW7KhER8SEFLAGgSWIUwzo3YWrOVopKvWu3kHjhhWAMee/P8ElNyVHJ3NT9Jr7b9h3fbfvOJ9cMGLEpcMUbcN4jsOFr+M9psOEru6sSEREfUcCSI8ZnZ5BXVMaMJdu8Ot/dpAmx2f3Je/99rMpKn9R0RYcraBnfkkd/fJTyynKfXDNgGAP9bqzayzAJXr8YZv3BM30oIiJBTQFLjujXOpn2jeN4fc4mrzupJ158MWXbtlG0wDfbxEQ4I7g7627W563n7TVv++SaAadJF7jxS+g1Ab573NMBft/PdlclIiL1oIAlRxhjGJ+dyfLtB1m4+YBX14g/+2xMTAx5M3wzTQgwpOUQ+jTpwzOLnyGvJETbG0TEwoin4PJXYe86eO4M+ClEA6WISBhQwJJjXNqzOfGRLiZ62bLBERNDwjlnc/DTmVSWlPikJmMMv+3zW/JK8nh+6fM+uWbA6nwJ3PIdNO4E71wH790GJfl2VyUiInWkgCXHiI10MbJ3Cz76aQd7DnkXkBJGjKDy0CHyv/zSZ3V1SO7AJadcwpSVU9h00DdPKQaspFZw9ccw8LeweDI8fybsWGJ3VSIiUgcKWHKccf0zKKuweOvHzV6dH9u/P660NPI++NCndd3R8w4inBE8vuBxn143IDldMOQBuOoDKC2EF86C758EHz08ICIi/qWAJcdplx7HgHYpTJ63mfKKuv8L3TidJAwfTv4331C+f7/P6kqNTuWaLtcwe/NsFu4Kk42TW58Bt3wPpw6Dzx+E10dA3la7qxIRkZNQwJJqTcjOZEdeMbNW7vbq/MQRF0JZGYd8sHXOMXV1mkBadBqPLXjM6ycdg05MMoyaCBc949le59nTtABeRCTAKWBJtc7qkE6zxChe93Kxe2SHDkS0a+vzacIYdwy397ydpXuW8vmmz3167YBmDPQc59k0Ou1UzwL4d26AogN2VyYiItVQwJJquZwOxvbP4If1uazbfajO5xtjSBx+oWfrnK3eNS6tyUVtL6JdUjueWPgEZeHWlDO5jWcvw8EPwLJ34LnTYWOIdbkXEQkBClhSo9F9WhLhdDBxjndP7SUMvwCAgx995MuycDqc/Lr3r9lyaAtT10z16bWDgtMFZ/4WrvscnG54dTh8/hCUl9pdmYiIVFHAkhqlxkVyQbemvLNwG/kldd+mJqJFC6J79uTghx/4vLbTm59Ov6b9eG7JcxwsPejz6weFFr09m0b3mgDfPwEvngV7VttdlYiIoIAlJzE+O4P8knKmL/TuybWE4RdQsnYdxavX+LQuYwy/7v1rDpQc4KWfXvLptYNKZJynA/yYKXBwG/x3IMx7HsLlAQARkQClgCUn1LNlEl2aJ3i9P2HCsGHgdPp8mhCgU0onhrcZzqQVk9iRv8Pn1w8qHS6AW+ZA5hnwyW9g4iVq5yAiYiMFLDkhYwwT+meydnc+czfsq/P5rpQUYrOzOfjRR35pq3BHzzsAeHrx0z6/dtCJbwxjp8Hwx2HLfHg2GxZP0WiWiIgNFLDkpEb0aEZSjJuJczd6dX7C8Aso27aN4iW+3+6lWVwzxnYaywfrP2DVvlU+v37QMQayrvU0J23cBd67Bd4cC/ne9TMTERHvKGDJSUW5nYzKasnM5bvYmVdc5/PjzzoLExFB3scf+6E6uL7r9SRGJvJYThg1Hz2Z5NZw9Ydw7sOwbhY80w+Wv2d3VSIiYUMBS2plXL8MKi2LKfPq3rLBGR9P3JkDOfTJp1gVFT6vLSEigZu63cTcHXP5fvv3Pr9+0HI44bTbPc1JG2XAtKvgneuhsO5TvSIiUjcKWFIrrVJiGNQ+jSnzt1BaXvf9CRPOP5/yPXso/DHHD9XB6FNH0yKuBY/lPEZFpe9DXFBLO9XTM2vwA7B8umdt1prP7K5KRCSkKWBJrU04LZO9+SV8unxnnc+NO/NMTHQ0Bz/5xA+Vgdvp5q7ed7HuwDpmrJ/hl3sENafb05z0hi88extOuRxm3AElde/SLyIiJ6eAJbV25ilpZKTEMNGL/QkdMTHEDx7Eoc8+wyqve9PS2hiaMZRuqd14etHTFJUX+eUeQa9pd7jxKxjwf7BoEvznNPj5W7urEhEJOQpYUmsOh2Fcvwx+3LifFdvr3j09/rzzqNi/n4K58/xQXVXz0axfs7toN1NWTvHLPUKCKxLO+SNc8yk4XPDacPj4t1BaYHdlIiIhQwFL6uTyrBZEuhxetWyIGzgQR2wsBz/1zzQhQO/GvRnYYiAvLXuJvJI8v90nJLTqBzd/B31vgvn/9azN2vC13VWJiIQEBSypk6SYCC7q0Yz3Fm0nr6isTuc6IiOJGzKE/M9nYZXV7dy6uLPnneSX5vPKslf8do+QEREL5/8TrvnE89Th6yPgg/+D4jDd31FExEcUsKTOJmRnUlRWwdsL6r4VS8J5w6jIy/PbNCHAqcmncn6b85m8cjK7C9Vgs1YyToObv4fs22Hha57RrLWz7K5KRCRoKWBJnXVpnkivVklMnLORysq6NfaMHTDAM00481M/VedxW4/bKK8s579L/uvX+4SUiBgY+jBc+5lnZGvySHjvVijab3dlIiJBRwFLvDIhO5ONuYV8u25vnc5rqGnClvEtuaz9Zbyz9h02Hax7c9Sw1rIP3PQNnP5rWPImPNMfVvmnC7+ISKhSwBKvnNe1CSmxEV61bEgYNtQzTTh/vu8LO8pN3W8iwhnBM4ue8et9QpI7Cs5+CG6YDTEp8OYV6gIvIlIHfg9Yxpi7jTGWMSbV3/eShhPpcnJF31bMXrWbLfsK63Ru7IABOGJiOPTpTD9V55Eancr4TuP5ZOMnrMxd6dd7haxmPT19swbd5+kC/0xf7WkoIlILfg1YxpiWwLnAZn/eR+xxZb9WGGBSHfcndERFETdoEIdmzfJb09HDru58NYmRiTy56Em/3iekuSJg0L1w49eQ0Myzp+Fb4+FQ3Tv6i4iEC3+PYD0O/Bao20poCQrNkqI5p1Njpv64heKyuu3/Fz90KBX791OYs8BP1VXdJyKeG7rewPfbvufHnT/69V4hr0kXuH42nPUgrJkJT/eFBa9CZd33phQRCXV+C1jGmIuAbZZlLfHXPcR+E7Iz2V9YxodLd9TpvLgzTsdERXHoM/9vOjz61NE0jmnMEwufwLKU9evF6YYz7oZbfoAmXeGDu+C1C2HvOrsrExEJKPUKWMaYWcaYZdV8XQTcDzxYi2vcaIzJMcbk7Nmzpz7liA1Oa5tC27TYOi92d8TEEHfGGRz6/HMsP4+ARLmiuLXHrSzds5Qvtnzh13uFjdR2cNUHcOFTsPMnz56G3zwKFf57MlREJJjUK2BZlnW2ZVldfvkFbABaA0uMMRuBFsBCY0yTaq7xvGVZWZZlZaWlpdWnHLGBMYYJ2Zks2ZrH4i0H6nRu/LnnUr5nD0WL/T/IOaLtCDITMnlq4VNUVNZtOlNq4HBA76vg9vlw6jD44s/w3zNhq3+nfUVEgoFfpggty/rJsqx0y7IyLcvKBLYCvSzL0qrYEHRpr+bERjh5vY6jWHGDzgS3m0Oz/N8x3OVwcWevO9mQt4EPNnzg9/uFlfgmMOp1GDPF05T0xbPgk3uhJN/uykREbKM+WFJv8VFuLunVnA+X7mBfQWmtz3PGxxOb3d8zTdgAa6PObnU2nVM689yS5yjTVJbvdbgAbpsHfa6Def+BZ/vD2s/trkpExBYNErCqRrLq1vJbgsqE7ExKyyt568ctdTov/pxzKNuyhZLVq/1U2f8YY7itx21sy9/G9HXT/X6/sBSVABc8BtfOBHcMTL7M06A0X+srRSS8aARLfKJ943j6t0lm0txNVNRhf8L4IUPA4eDQZw0z0nF689PpkdaD55c+T0lFSYPcMyy16g83f1vVoPQ9eKYPLHxdLR1EJGwoYInPTMjOZNuBIr5YtbvW57hSUoju1ZNDXzTM033GGG7veTu7Cnfx9pq3G+SeYcsV6WlQevN3kNYRZtwBr54Pu9VVX0RCnwKW+Mw5nRrTOCGyzovd4886m5JVqyjdutU/hf1Cv6b96NOkDy8sfYGi8qIGuWdYS+8AV38EFz0De1bDc6fDrD9Aad22WBIRCSYKWOIzbqeDsf0y+HbtXjbsqf0TZPFnDQHg0Of+f5rwsNt73E5ucS5vrXqrwe4Z1hwO6DkObs+BbmPgu8fh2X6ejvAiIiFIAUt8akyflrgchinzar/9ZESrVkS2b0/+7Nl+rOxYvRr3YkCzAby07CUKygoa7L5hLzYFLn4Grv4YXNEwZRS8NQ7yttldmYiITylgiU+lJ0QxtHMTpi3YWqf9CePOGkLhwoWU79/vx+qOdVuP2zhQcoDJKyc32D2lSuYAz9qssx70tHJ4pi/MeRYq/Lv5t4hIQ1HAEp8b1z+DvKIyPliyvdbnxA85Cyoryf/qaz9WdqyuaV0Z1GIQry5/lYOlBxvsvlLFFeHZ1/DWudAqG2beBy8MVid4EQkJCljic/3bJNMuPY5JczfV+pyoLp1xNW7ModkNtw4L4Laet3Go9BCvL3+9Qe8rR0luDWOnweWvQcEeTyf4j+6GogN2VyYi4jUFLPE5Ywzj+rViydY8lm49UOtz4oYMpuD7H6gsabj+VB2SO3BOxjlMWjmJ/cUNNz0pv2AMdL4YbpsP/W6CnJc904ZLp0EDdPkXEfE1BSzxi0t7tyDa7azTKFb8kCFYRUUUzp3rx8qOd2v3WyksK+SV5a806H2lGlEJcN4/4IYvIKEZvHs9vDpcvbNEJOgoYIlfJES5ubhnM2Ys2U5eYe32/Yvp1w9HTAyHvvjSz9Udq12jdpzf5nzeXPUme4u0o1NAaNYTrp8Nwx+H3cvhPwNg5gNQrLVyIhIcFLDEb8b2y6C4rJK3F9augagjIoLYAQPI//LLBtn8+Wi3dL+F0opSXvrppQa9r5yAwwlZ18LtCzw9tOY8A0/3gZ/e1rShiAQ8BSzxmy7NE+nZKonJczfVOjDFDRlC+e7dFC9f4efqjpWRkMGFbS9k2ppp7CnUxsQBJTYFRjzlGdFKaArvXKdpQxEJeApY4lfj+mWwYW8BP6zPrdXxcQPPAGPI/+or/xZWjRu73kh5ZbnWYgWqFr01bSgiQUMBS/zqgm5NSYpx13qxuyslheju3W0JWC0TWnJBmwuYtnqa1mIFKk0bikiQUMASv4pyOxmV1ZLPVuxiZ15xrc6JGzSI4mXLKNu128/VHe/GbjdSWlnKa8tfa/B7Sx1o2lBEApwClvjd2H6tqKi0ePPH2u1PGDd4EAD53zRcV/fDMhIyOL/1+by1+i1yi2o3rSk20rShiAQoBSzxu4yUWAa2T+ON+Zspq6g86fGR7dvjatKE/K8bPmAB3NDtBorLi3l9hbq7B4Xqpg3/3QsWToTKk//zJiLiDwpY0iDG989g18ESZq/cddJjjTHEnXkmhT/MobK0tAGqO1abxDYMyxzGG6veUHf3YHJ42vCGL6BRa5hxu2fbnS0/2l2ZiIQhBSxpEEM6pNMsMYpJc2s5TXjmmVQWFlKUk+Pnyqp3Y7cbKS4vZuKKibbcX+qheS+47jO45Hk4tANeOhvevQkO7rC7MhEJIwpY0iCcDsOV/Vrx3bq9bNiTf9LjY/v3w0RE2DZN2K5RO87JOIcpq6aQV5JnSw1SD8ZA99Fwew6c/mtY/i78uzd8+y8ob7i9LkUkfClgSYMZ1aclLodh8ryTj2I5YmKI6duX/G++bYDKqndT95soKCvQKFYwi4yDsx+C2+ZBm0Ew+4/wTD9Y9bHaOoiIXylgSYNJj49iaJcmTMvZQlFpxUmPjxt4BqU//0zpli0NUN3x2jdqz9mtzmbyyskcLNVTaUEtuQ1cMQXGTwdnBLx5BUy6FPastrsyEQlRCljSoMb3z+BgcTkfLN1+0mPjBg4EIP+bb/xdVo1u6n4T+WX5TF4x2bYaxIfaDoFbvodhf4etC+A/p8Gn90HRAbsrE5EQo4AlDapf62ROSY+rVWf3iMxM3K1aUWDjNGGH5A4MbjmYiSsnkl968rVjEgScbuh/C9y50NPWYe5/POuzFrwKlScfWRURqQ0FLGlQxhjG9c9g6dY8lmw5cNLj4844g4L586kssW9h8k3dbuJQ6SGmrplqWw3iB7GpcOGTcONXkHoKfHAXPD8INn5nd2UiEgIUsKTBXdKrOdFuZ61GseIGnoFVVETRggUNUFn1Oqd2JrtpNq8vf53i8tpt9yNBpFkPuOYTGPkSFO6DVy+AN8dC7nq7KxORIKaAJQ0uIcrNxT2bM2PJdvIKy054bEyfPp52DTZOEwJc3/V6cotzeX/d+7bWIX5iDHS9DO7IgSG/h/Vfep42nPmA1meJiFcUsMQW4/q3oqS8kmkLTvyEoCMmhpisLPK/szdg9WnSh25p3Xhl+SuUV5bbWov4kTsaBv7Gsz6r+xjPtjtP9YT5L0CFPncRqT0FLLFF52aJ9GqVxOR5m6msPHE/otjTT6d03XrKdtjXidsYw/Vdrmdb/jY++fkT2+qQBhLfBC56Gm76Bhp3ho/v8TxxuPZzuysTkSChgCW2Gdc/g5/3FvDD+twTHhd7+gAACr7/viHKqtGZLc+kXVI7Xl72MpWWNhEOC027wVUfwJgpUFkGky+DiZfCrhV2VyYiAU4BS2xzftemNIpxn3Sxe+Qpp+BKTyff5oDlMA6u63od6w6s46stX9laizQgY6DDBXDrPBj6N9iWA88NgA9/Bfl77K5ORAKUApbYJsrtZFRWSz5fuYudeTU/nWeMIXbAAAp/mINVYW+fomGZw2ge15wXf3oRS1uthBdXBGTfCncuhj43wILX4N+94LsntL+hiBxHAUtsdWW/VlRaFm/MP/H+hLEDBlCRl0fx8uUNVFn1XA4X13a5lp/2/sT8nfNtrUVsEpMM5/8Tbp0LGafBrIfg6T6w/D3tbygiRyhgia0yUmIZeEoab8zfTFlFzeuaYk/LBqDghx8aqrQaXdTuIlKjU3nxpxftLkXslNYernwLxr8HEXEw7Sp45TzYmmN3ZSISABSwxHbj+2ew+1AJs1bsqvEYV3IykZ06UvC9/QEr0hnJhE4TmLtjLsv2LrO7HLFb28Fw87cw/AlPc9IXz4JpV8O+DXZXJiI2UsAS2w3ukE7zpGgmzTvxYve4006jcPFiKgsKGqiymo06dRTxEfEaxRIPhxOyroE7F8GZ98KamfB0X/jkXig48VOyIhKaFLDEdk6HYXSflny/LpeNe2sOT7GnnQZlZRTm2D8FE+uO5coOVzJ782w2HNBIhVSJjIPB93mCVo8rYf5/PY1Kv3scyorsrk5EGpAClgSE0X1a4nQY3vix5sXu0b17YyIjA2IdFsDYjmOJckbx+orX7S5FAk18ExjxFNzyA2Rkw6w/wL+zYMmbUKkeaiLhQAFLAkLjhCjO6pDO2zlbKS2v/l9AjshIonv1pGDO3AaurnqNohpxUbuLmLF+BnuL9tpdjgSi9I6ehfBXfQCxqTD9Jnh+oGevQxEJaQpYEjCu6NeK3IJSPluxs8ZjYrNPo2TNGspzA2Ndy/hO4ymvLGfKyil2lyKBrPVAuOFLuPRFKMqDiRfDpJGwy962IyLiPwpYEjAGnpJG86ToE/bEis3uD0DB3MAYxcpIyOCsVmfx1uq3KCwrtLscCWQOB3S7HG7/Ec79C2z9EZ47Hd6/DQ5ut7s6EfExBSwJGE6HYcxJFrtHdeqEIyGBgjlzGri6ml3V+SoOlh5k+rrpdpciwcAdBafd4ekI3/9WWDoVnuoFs/8MxQftrk5EfEQBSwLKqMOL3WsYxTJOJzF9+1A4L3C6qPdI70GPtB5MXDGR8spyu8uRYBGTDEMf9oxodbgAvn3U88Th/Begoszu6kSknhSwJKA0Toji7I7pTFuwlZLy6vcdjO3Xn7ItWyjduq2Bq6vZ1Z2vZlv+NmZvnm13KRJsGmXCZS/BDV9AWgf4+B54pi8se0dPHIoEMQUsCThX9G3FvoJSPltefWf32P79ACicN68hyzqhQS0HkZGQwavLXtUm0OKd5r3h6g/hyqngioa3r4UXBumJQ5EgpYAlAedki90j2rXDmZJCwbzAWOgO4HQ4mdBpAstyl7Fg1wK7y5FgZQy0H+rZeufi56Bwv+eJw9cvgu2L7K5OROpAAUsCjsNhuKJvS35Yn8vP1Sx2N8YQ268vhXPnBdRo0Yi2I2gU2YhXl79qdykS7BxO6HEF3JEDQ/8GO5bC84M8exzmrre7OhGpBQUsCUijslriOsFi95i+/SjfvZuyzTW3dGhoUa4oruhwBV9v/ZoNedo+R3zAFQnZt8Jdi2Hgbzx7HD7TFz78NRyqeXN0EbGfApYEpPSEKM7u2Ji3a1jsHtO3LwAF8wPnaULwbALtdrjVeFR8KyoRhvze09qh99Ww8DV4qkdVa4c8m4sTkeooYEnAuqKfZ7H7zGoWu0e0zsSZlkrh/B9tqKxmKdEpnN/6fGasn8HBUvU0Eh+LbwwXPAa3zYf2wzytHZ7sAXOegfISu6sTkaMoYEnAOqNdKi0aRfPGvOOnAY0xxPbpS+H8+QG1DgtgXKdxFJUXMX2tGo+Kn6S0hctfgRu/gqbdYeb98O/esHgKVFbf3kREGpYClgQsz2L3VszZkMuGPfnHvR/Tty/lu3YF1DosgA7JHejduDdTVk5R41Hxr2Y9YcJ7MP49iEmB927xbL+z+lMIsP/wEAk3ClgS0C7PalHjYveYPlkAFObkNHRZJzWu4zi2F2znqy1f2V2KhIO2gz2bSV/2CpQXwxuj4ZXzYHPg9IoTCTcKWBLQ0uNrXuwe0aYNzkaNKPwx8ALW4JaDaRbbjEkrJ9ldioQLhwO6XOpZn3XBv2DfBnj5XHjjCti1wu7qRMKOApYEvCv7tWJ/YRmfLtt5zOvGGGKysgJyBMvpcHJFhytYsGsBq/atsrscCSdON/S5Du5c5HnycON38J/T4N0bPaFLRBqEXwOWMeYOY8wqY8xyY8w//XkvCV2nt0ulZXL1nd1j+mRRtnUrZTt22FDZiV1yyiVEu6KZtEKjWGKDiFhP76y7lsCAu2DFDHi6D3z4KzgYeH9fREKN3wKWMWYwcBHQ3bKszsCj/rqXhDaHwzCmTyvmbtjH+l8sdo/JCtx1WImRiYxoO4KPf/6Y3KJcu8uRcBWTDOf80dOstPfVsPB1Tw+tz/4fFO6zuTiR0OXPEaxbgL9bllUCYFnWbj/eS0Lc5VktcDoMU3O2HPN65Kmn4oiNpXBBYO7/d2XHKymrLGPamml2lyLhLr6Jp4fW7TnQ+RL44d/wZHf4+p9Qcsju6kRCjj8DVnvgDGPMPGPM18aYPn68l4S49PgoBp+azjsLtlFWUXnkdeN0Et2zJ0ULFtpYXc3aJLZhQPMBvLX6LcoqyuwuRwSSW8Mlz8Gtc6D1QPjyYU/QmvMMlBXbXZ1IyKhXwDLGzDLGLKvm6yLABSQD/YHfAFONMaaaa9xojMkxxuTs2bOnPuVIiBvdpyV780v4avWx/5zEZPWmZO1aKvICc8uQKztcyd6ivczePNvuUkT+J70jjJkM138BTbpWNSvtBQtegwr1bxOpr3oFLMuyzrYsq0s1X+8DW4F3LY/5QCWQWs01nrcsK8uyrKy0tLT6lCMhbtCpaaTGRfLWj8dOE0b36gVA4aJFdpR1UgOaDaB5XHPeWv2W3aWIHK9Fb5jwPkyYAfFN4YM7PRtKL3sHKitPfr6IVMufU4TvAYMBjDHtgQhgrx/vJyHO7XQwsndzvly9m92H/jeVEd21K7jdFAXoOiynw8moU0eRsyuHdfvX2V2OSPXanAnXz4Ixb4ArEt6+Fv47ENbMVFd4ES/4M2C9DLQxxiwD3gSusgJt0zgJOpf3bklFpcW7C7cdec0RHU1Up44BO4IFcHG7i3E73ExdM9XuUkRqZgx0OB9u/g4ufRFK82HKKHh5GGz83u7qRIKK3wKWZVmllmWNq5oy7GVZ1hf+upeEj3bpcWRlNGJqzpZjNnmO6dmL4p+WYZWW2lhdzZKjkhmaOZQZ62dQWFZodzkiJ+ZwQrfL4fYfYfjjcGATvHo+TBoJ2xfbXZ1IUFAndwk6o7JasmFPAQs27T/yWnTPnlglJRSvXGljZSc2+tTRFJQV8OGGD+0uRaR2nG7IutbTFf6cP8O2BfD8mTB1AuxZY3d1IgFNAUuCzgXdmhIT4TymJ1Z0jx5A4C50B+ie1p1TG53KW6vfQrPlElTc0TDgTk9X+DN/B+tmw7P94L3b4MDxOyyIiAKWBKHYSBfDuzXlw6U7yC/xPE7ubpyOu3lzihYttre4EzDGMLrDaNbsX8OSPUvsLkek7qISYfD9nqDV/1b4aRr8uzd8/FvIVy9pkaMpYElQGt2nJYWlFXy89H97qkX37EnRokUBPTp0QesLiHPHqWWDBLfYVBj6MNy5ELqPgR9f9DQrnf0nKNp/8vNFwoAClgSlXq0a0SYtlreOnibs3p3y3bsp37nTxspOLMYdw/A2w/ls42fklQRmY1SRWktsASP+7VkMf+r58O1jnqD17WNQWmB3dSK2UsCSoGSMYXRWSxZs2s+63Z4NoKN7dAegaElgT7+NbD+S0spSPtrwkd2liPhGSlu47CVPe4dWp3lGsp7sDvP+C+UldlcnYgsFLAlal/bybAA9rWoUK+rUUzERERQtDuyA1SG5A51SOvHO2ncCejpTpM6adIUr34TrPoe0DvDJbz1rtBZN0vY7EnYUsCRopcVHMqRDOu8s9GwAbSIiiOrcOeBHsABGnjKSNfvXsCJ3hd2liPhey75w1Qcw/j2ITYP3b4Nn+8Py6dp+R8KGApYEtdFZng2gv1zleYIpunt3ipcvD9iGo4ed1/o8ol3RvL32bbtLEfEPY6DtYLjhCxg9GRwumHa1p4/W2s+1/Y6EPAUsCWqeDaAjjmydE929G1ZpKcVr1tpc2YnFR8Rzbsa5fLzhY3V2l9BmDHQcDrd8D5c8D8V5MPkyeOU82PSD3dWJ+I0ClgQ1l9PBhd2b8cWq3eQVlhHVtRsAxT8ttbmykxvZfiSF5YXM3DjT7lJE/M/hhO6j4fYcuOBfsO9nT8iaNBK2B26DYBFvKWBJ0BvZqwWlFZV8+NN23M2b4WzUiKKfltld1kn1SOtB68TWvLv2XbtLEWk4rgjoc90vtt8ZVLX9zmq7qxPxGQUsCXqdmyVwSnoc0xduwxhDVLeuQTGCZYxh5CkjWbxnMev2r7O7HJGGFRFz1PY791Ztv9Mf3rsV9m+yuzqRelPAkqBnjOGSXs3J2bSfTbkFRHfpSsn6DVQWBH6jwwvbXojLuHhv3Xt2lyJij6hEGHzfUdvvvF21/c5v4NAuu6sT8ZoCloSEi3s0xxiYvmgb0d26QmUlRcuX213WSSVHJXN6i9P5+OePqaissLscEfsc2X5nEfQcBz++5GlWOusPULjP7upE6kwBS0JCs6RostukMH3RNiI7dwageHlw9Jga0XYEe4r2MG/HPLtLEbFfYnO48AnP9jsdL4TvnoAne8A3j0BJvs3FidSeApaEjEt6NmdTbiFLC5y4mjShOAhGsADObHEm8RHxzNgww+5SRAJHSlsY+YKnvUPm6fDFXzwjWnP/A2XFdlcnclIKWBIyzuvalCi3g+mLthLVuXPQBKwIZwTDMocxe9NsCsoCf92YSINq3BmumALXzYLGneDTez1rtBa+ru13JKApYEnIiIt0cW6nJnywZAfujh0p3biRivzgCCwj2o6guKKYzzd9bncpIoGpZR/P9jsT3of4xjDjDni2Hyx7R9vvSEBSwJKQckmv5uQVlbEqoTlYFiUrg2MdVve07rSMb8mH6z+0uxSRwNZmEFw/G8ZMAWcEvH0t/HcgrJmp7XckoChgSUg5o10qqXGRvF8QDxAUTxKCp9XEhW0uZP7O+ezI32F3OSKBzRjocAHc/B1c+gKUHoIpo+DlobDxO7urEwEUsCTEuJwOLurRjA+3luBIS6N4RXCMYAEMbzscC4uPfv7I7lJEgoPDCd1GebbfGf44HNgMr14AEy+BbQvtrk7CnAKWhJxLejanrMJif7NMSlYFz9YbLeNb0iu9FzPWz8DSVIdI7TndkHWtp4fWuX+B7YvhhcHw1jjYvcru6iRMKWBJyOncLIE2qbH8FNWYkg0bqCwpsbukWhvedjg/5/3Min3BM/ImEjDc0XDaHZ6u8IPug/VfwX+yYfrNsH+j3dVJmFHAkpBjjGF4t6Z8azWC8nJK1gXPPn/ntDoHl3Ex8+eZdpciEryiEmDQvZ6glX0bLJ8O/86Cj+6GQzvtrk7ChAKWhKTh3ZuxLqEZACWrgmeKICkqif7N+jNz40xNE4rUV2yKZ8rwzkXQazwseNXTFf7zh6Bov93VSYhTwJKQ1L5xPPFtMihxR1K8MngCFsCwzGFsL9jO0r1L7S5FJDQkNPMsgj+8/c73T3qC1vdPqSu8+I0CloSsC7q3YH18Uw4tC45WDYcNaTUEt8PNpz9/ancpIqEluY1n+52bv4UWWfD5/4Ons2DxG6DN1sXHFLAkZA3v1pSfE5pQvGZtUE23xUfEM6D5AD7b9BmVljpUi/hck64w7h2YMANiUuC9m+G5M2Dt52pWKj6jgCUhq01aHCUtW+MqzKd81y67y6mTYZnD2F24m0W7F9ldikjoanMm3PAlXPYylBXA5MvgtQth2wK7K5MQoIAlIS2zbzcAti38yeZK6mZwy8FEOaOYuVFPE4r4lcMBXUbCbT/CeY/A7pXwwhCYehXkrre7OgliClgS0k4/ux8Ay78LrpGgGHcMpzU7jdmbZ2uaUKQhuCKg342eJw7P/J1nuvCZvvDRPZC/2+7qJAgpYElIy2jdlLzYJPYvX2l3KXV2VsZZ7C7czfK9wbVIXySoRSXA4PurWjtcBTkvw1M94au/Q0m+3dVJEFHAkpBXkdmGpJ2b2bKv0O5S6uTMFmfiNE5mb55tdyki4Se+MQz/F9w2H9oOga/+Bk/1gB9fhIpyu6uTIKCAJSEvvVtnWh3axcyl2+wupU4SIxPJapKlgCVip9R2MHoiXDcLUk7xdIN/boBnClHkBBSwJOSlde2Iu7KCBXOW2V1KnZ3d6mw2HtzIhgMb7C5FJLy17APXfAyjJ0NFqeeJw4mXwC5N4Uv1FLAk5EW2bQPAgVVr2JsfPBs/g+dpQkCjWCKBwBjoOBxunQdD/wbbFsJzp8MHd2khvBxHAUtCXkQbT8BqcWg3s1YEVz+sxrGN6ZbaTQFLJJC4IiD7Vs9C+H43w6JJnoXw3zwKZUV2VycBQgFLQp4zPh5XejodSnKZuXyn3eXU2ZBWQ1ieu5xdBcEVDkVCXkwyDPubZ0SrzSD44s/w7yxYOg0q1V4l3ClgSViIaNuGDqW5fL8ul0PFZXaXUycDWwwE4Ltt39lciYhUK7UdjJkMV38EsSnw7vXw4lmwaY7dlYmNFLAkLES2aUujvdspLa/gq9V77C6nTtoltaNJbBMFLJFAl3k63PAVXPwcHNoJrwyDqRNg/ya7KxMbKGBJWIho2wZTVEg7RyGzVwbXVJsxhjOan8GcHXMoqwiu0TeRsONwQI8r4I4FMOh+WPOZpyP8l3+D0uDqxSf1o4AlYSGyTVsAhsUX8/WaPVRUWjZXVDdnND+DgrICbf4sEiwiYmDQ7+COHDj1fPj6756gtfw9sILr/3/EOwpYEhYiMjMA6OMqYH9hGYu3HLC3oDrq17Qfboebb7d9a3cpIlIXiS3g8lc867OiEmHaVfDahbBrhd2ViZ8pYElYcKWnY6KiaF2yD4eBr1YHV8+aGHcMvRv35tutClgiQSnzdLjxazj/Udj5k6d/1se/haL9dlcmfqKAJWHBOBxEtGqF2baV3hmN+GJVcAUs8EwTrs9bz7b84NryR0SqOF3Q9wZP/6ysa+DHF+CpXpDzClRW2F2d+JgCloSNiIwMSjdtYnCHdJZvP8iug8V2l1QnZ7Q4A4DvtuppQpGgFpMMFzwGN30D6R3hw/+DF4Z4OsNLyFDAkrARkZlB6datDG6XDATfNGFmQiZNY5syb+c8u0sREV9o0tWzNmvkS562Di8M8WwmXXTA7srEBxSwJGxEZGRAWRltKvNpmhgVdNOExhj6NOnD/J3zqbTUJVokJBgDXS+D2+dDv5sg52V4ug8snaqnDYOcApaEjYgMz5OEZZu3MLhDOt+t3UtZRXAFlX5N+5FXksfa/WvtLkVEfCkqEc77B9zwpefJw3dvgNdHwF79XQ9WClgSNtxVAat000ZOb5dKQWkFS7cesLeoOurbpC8A83fOt7kSEfGLZj3g+lmeNVrbl8B/ToMv/qJNpIOQApaEDVdaGiYqirItW8luk4Ix8P26XLvLqpMmsU1oGd+S+TsUsERClsMJfa73NCntfAl88wg82x/Wf2F3ZVIHClgSNowxuJs3p2zbNhrFRtCpaQLfr9trd1l11rdJX3J25VBeWW53KSLiT3HpcOnzMGEGOFww8RJ471Yo3Gd3ZVILClgSVtzNm1G2zdNHakC7VBZtPkBRaXD1n+nbpC/5Zfms2rfK7lJEpCG0ORNu/h7OuBuWvAnP9IPl07UIPsApYElYOTyCBXBa2xRKKyr5cWNw/ddgnyZ9AK3DEgkr7ig460G48StIaArTroa3xsHBHXZXJjXwW8AyxvQwxsw1xiw2xuQYY/r6614itRXRvDkVeXlU5OfTt3Uybqfh+/XBNU2YFpNGm8Q2Clgi4ahpN7j+CzjnT7Bulmc0a8FrGs0KQP4cwfon8EfLsnoAD1b9LGIrd/PmAJRt205MhIueLRvxQ5AtdAfPKNbCXQu1DkskHDldMOAuuOUHT+D64E5PS4cDW+yuTI7iz4BlAQlVf04EtvvxXiK18r+AVTVN2C6FZdvzOFBYamdZddYrvRdF5UWs2b/G7lJExC4pbT0L4Ic/4dlm5z+nwaLJGs0KEP4MWP8HPGKM2QI8Ctznx3uJ1MovA9aAdqlYFszdEFyjWD3TewKwePdiewsREXs5HJ6No2/53rP1zvu3wptXQn5w7VQRiuoVsIwxs4wxy6r5ugi4BfiVZVktgV8BL9VwjRur1mjl7Nmzpz7liJyUMznZ0wurKmB1b5FElNvBvJ+Da6F7k9gmpMeks3jPYrtLEZFA0CgTrvoQzn0Y1s329M1a8b7dVYW1egUsy7LOtiyrSzVf7wNXAe9WHToNqHaRu2VZz1uWlWVZVlZaWlp9yhE5KWMM7mbNKNu2FYAIl4MeLZPI2bjf5srqxhhDj7QeLNm9xO5SRCRQOBxw2u1w0zee7XamToB3b9Tm0Tbx5xThduDMqj8PAbShkgQEd5MmlO363/B5n8xklm/PI78kuBaM90jvwfaC7ewq2GV3KSISSNI7wPWz4czfwU9vw7PZ8PO3dlcVdvwZsG4AHjPGLAH+Ctzox3uJ1JqrcWPKdx8bsCotWLz5gH1FeaFbWjcAlu1dZnMlIhJwnG4YfD9c/zm4o+G1C+GLh6EiuP5DMpj5LWBZlvWdZVm9LcvqbllWP8uyFvjrXiJ14UpPp3zPHqwKTwf3nq2ScBiCruHoqY1OxWVcLM9dbncpIhKomveGm76G7lfAN/+E14arnUMDUSd3CTuu9DSoqKBinydQxUe56dAkgYWbg2sdVpQrinaN2ilgiciJRcbDJf+BS1+AnT/Bc6fDyg/srirkKWBJ2HGlpwNQdtQ0YY9WSSzecoDKyuDqH9M5pTPLc5djqe+NiJxMt1GeBfCNMj3b7Hz4aygrtruqkKWAJWHH3bgxAOVHLXTv0TKJQ8XlbNhbYFdZXumc2pm8kjy25m+1uxQRCQYpbeG6zyH7dsh5CV4+F/ZvsruqkKSAJWHn8AjW0Qvde7ZMAmDxlgM2VOS9LildAFi+V9OEIlJLrggY+jCMeQP2bYTnz4S1s+yuKuQoYEnYcaWkgDHHBKy2aXHER7pYvCW41mG1S2qHy+Fi5b6VdpciIsGmw/lw45eQ0BwmXwZf/R0qK+2uKmQoYEnYMW43ztQUyvf8L2A5HIZuLRODbgTL7XTTJrGN9iQUEe8cnjLsPga++htMGQVFwfUfmoFKAUvCkjstnbJdxzbo7No8idU7D1FaHlz/BXdqo1MVsETEexExcPF/4IJ/wYav4MWzYe86u6sKegpYEpZc6emU7z5278vOzRIoq7BYs+uQTVV5p32j9uwu3M2B4gN2lyIiwcoY6HMdXDXDM4L14hBY/6XdVQU1BSwJS67GjSn/xQhW52YJAKzYftCOkrzWvlF7AI1iiUj9ZZwGN3zhWZc1aSTMf8HuioKWApaEJVdKMhUHDhzp5g6QmRJLbIST5dvzbKys7tonK2CJiA81yoTrPoNTzoWP7/H0y9IWO3WmgCVhyZmUBJZFxcH/jVY5HIaOTRNYHmQjWKnRqSRHJbN6/2q7SxGRUBEZD2Mmw4C7PP2y3rwSSoOrT6DdFLAkLDkbNQKgYv+BY17v3CyBlTsOBl1H93ZJ7diQt8HuMkQklDiccM6fPIvf130Or42Agly7qwoaClgSlpxJSQBUHDhwzOudmyVSUFrB5n2FDV9UPWQmZLIxb6O2zBER3+tzHYx63bOPoTq/15oCloQlZ1LVCNaBY/u9nNI4DiDoniRsndiag6UH2Ve8z+5SRCQUdbwQJrwPBXvgpXNgx1K7Kwp4ClgSlpyNkoDjpwhPaRwPwNrd+Q1cUf20TmwNwM95P9tciYiErIxsuHYmOFzwyvmwaY7dFQU0BSwJSzWNYMVFumiWGMXaIBvBykzMBGDjwY221iEiIS69o6fze3xjTxuHn7+xu6KApYAlYckRGwNu93FrsMAzirVmV3CNYDWNbUqkM1IjWCLif4nN4eqPIaklTL4c1s22u6KApIAlYckYgyspifL9x++51b5xHOv35FMRRE8SOozDs9BdI1gi0hDiG8PVH0HKKfDGGFj9qd0VBRwFLAlbzqSk6kew0uMpKa9kS7A9SZiYqREsEWk4samerXUad4ap42H9F3ZXFFAUsCRsORs1qmGK0PMkYbAtdG8Z35Id+TuoqKw4+cEiIr4Qkwzjp0PqqfDGlbDpB7srChgKWBK2nElJxz1FCNAm1ROwNu4Nrq7FzeKaUW6Vs6doz8kPFhHxlehGnpCV2AImj4JtC+yuKCAoYEnYqmkEKzHGTWK0m037gitgNY9rDsDWQ1ttrkREwk5cmme6MCYZJl4Ku5bbXZHtFLAkbB1eg1Vd9/PMlBg25QbXGqzDAWt7wXabKxGRsJTQzBOy3NEw6TI4GN7/X6SAJWHL2SgJKiqoPHR8z6tWKbFBF7CaxjYFYFv+NpsrEZGw1SgTrpwKJQc904XFB+2uyDYKWBK2juxHWE2rhozkGLYdKKKsorKBq/JehDOC9Oh0tueH9381iojNmnaDUa/B7hUw7WqoKLO7IlsoYEnYciYkAlBx8PgRrIyUGCoqLbbtL2rosuqlWVwzBSwRsV+7s+HCJ2D9bPjo1xCGG9ErYEnYcsREA1BZdPxUYEZKLACbgqwXVrO4ZpoiFJHA0GsCnHEPLHwd5v3X7moanAKWhC1HtCdgWUXHj1JlpMQAsDk3+J4k3FWwi/LKcrtLERGBwQ/AqefDZw+EXY8sBSwJW44YT4iqrCZgpcdHEuV2sDHIFrof6YVVqF5YIhIAHA645DlIyoCpV8HBHXZX1GAUsCRsmeiqgFVwfIgyxtAsMZqdecUNXVa9pEWnAbC3aK/NlYiIVIlKhNGToLQApl0F5aV2V9QgFLAkbDliax7BAmicEMXOg8EVsFKjUwEFLBEJMI07wUVPw5Z58Nnv7a6mQShgSdg6vAarsrD6acCmiVFBN4KVEp0CwN5iBSwRCTBdLoX+t8H8/8LqT+yuxu8UsCRsmchIMKbapwgBGidGsetgMZWVwfN4cUpUVcDSCJaIBKKzH4ImXeH92+DQLrur8SsFLAlbxhgcMTFYhdVPETZNjKK80iK3IHjWC7idbpIik8gtyrW7FBGR47kiYeRLnvVY798a0v2xFLAkrJmY6BqnCBsnRAGwKwjXYWkES0QCVtqpcO5fYN0syHnZ7mr8RgFLwpojOqbGRe5NqgLWjiBch6WAJSIBrc/10GYQfP4Q5IVmc2QFLAlrjpiYEy5yB4LySUJNEYpIQDMGhj8BVkXIbqWjgCVhzREdXeMi95S4SJwOw65gG8GKSiG3OBcrBP8PS0RCSHJrGPJ7WPMpLHvH7mp8TgFLwtqJFrk7HYb0+MigmyJMjU6lqLyIwvLg6kIvImGo383QvDd8eh8UH7S7Gp9SwJKw5jjBIneAJlWtGoKJmo2KSNBwOOH8R6FgD3zziN3V+JQCloQ1Ex1d4yJ38OxJuOdQSQNWVH9Hmo0qYIlIMGjeC3qOhbn/gb3r7K7GZxSwJKw5Ymp+ihAgKTqCA0XB0wcLNIIlIkFoyIPgioKZ99tdic8oYElYc0TX/BQhQFKsm/2FZUG1YDwxIhGAg6WhtZ5BREJYfGM487ewdias/9LuanxCAUvCmiMmBquoCKuystr3k6IjKC2vpLis+vcDUVxEHAD5pfk2VyIiUgf9boKEFvDFX0KibYMCloQ1R4xnw2erhmnCpBg3QFBNE8a4YnAYB/llClgiEkRckTDwHtiWA2s/s7uaelPAkrBmoj0Bq6Z1WI2qAtb+grIGq6m+jDHEumM1giUiwafnOEjKgC8fDvpRLAUsCWuOmBig5oCVGB0BBNcIFkCcO04jWCISfJxuOPN3sGMJrPrQ7mrqRQFLwpojuipg1bDQ/fAUYV5h8IxggWcdlkawRCQodRsNyW09fbGCeBRLAUvC2uE1WDUFrEYxnhGs/UEWsOLd8RrBEpHg5HTBabd7RrE2z7G7Gq8pYElYOzJFeJIRrGCbIox1xypgiUjw6jYGohvBnGfsrsRrClgS1hzRJ36KMMrtJNLl4ECQjWBpilBEglpEDPS+BlZ9BPt+trsaryhgSVg72SJ38EwTHigMrhEsTRGKSNDre4Nnr8J5/7W7Eq8oYElYM4cDVkFBjcckxbiDbgQrNkJtGkQkyCU0g86XwqKJUBx8O1MoYElYcyYlAVCxf3+NxyRGB1/AinfHU1pZSmlFcI28iYgco9/NUJoPy962u5I6U8CSsOaIiMCRmEj5npo3Rk6KcQfdIvfD2+UcKj1kcyUiIvXQvBekd4KFE+2upM7qFbCMMZcbY5YbYyqNMVm/eO8+Y8w6Y8xqY8zQ+pUp4j+u1FTK99YcsDxrsIJrBCvO7QlYBWU1T32KiAQ8Y6DneNi+EHYtt7uaOqnvCNYy4FLgm6NfNMZ0AsYAnYFhwLPGGGc97yXiF67UVMpzc2t8P7FqDZYVRA3vDgesQ2UawRKRINdtNDhcsORNuyupk3oFLMuyVlqWtbqaty4C3rQsq8SyrJ+BdUDf+txLxF9cKSmU791T4/sJUW5KKyopKa9swKrq5/AUoRa6i0jQi02BdmfDsnegMnj+f9hfa7CaA1uO+nlr1WsiAceVlkrFCdZgRbs9g68lZcHzF/vwCJZaNYhISOhyGRzcBlvm2l1JrZ00YBljZhljllXzdZEvCjDG3GiMyTHG5OzZU/Mogoi/OFNTqSwsrLFVQ6Tb89ekuLyiIcuqF41giUhIOfU8cMfAT8HzNKHrZAdYlnW2F9fdBrQ86ucWVa9Vd/3ngecBsrKygmeRi4QMV0oqAOW5uUTExh73fqQr+Eaw4t3xgEawRCRERMZBu7Ng9cdw/qPgCPwmCP6qcAYwxhgTaYxpDZwCzPfTvUTqxZVWFbD2Vr/QPdLl+WtSEkQjWLERnqCoESwRCRkdhsOhHbB9kd2V1Ep92zRcYozZCmQDHxljZgJYlrUcmAqsAD4FbrMsK3j+7SRhxZV6OGBVP0X9v4AVPCNYboebKGeURrBEJHScci4YJ6z+yO5KaqW+TxFOtyyrhWVZkZZlNbYsa+hR7z1sWVZby7JOtSzrk/qXKuIfzpQUgBp7YUUdXuQeRCNYALHuWPXBEpHQEZMMGafBqo/trqRWAn8SU8TPXMnJYAwVNQSswyNYxUG0BgsgyhVFSUWJ3WWIiPjOKefAnpVwcLvdlZyUApaEPeNy4UxOrnkNVpCOYEU6IykuL7a7DBER32k7xPN9/Zf21lELClgiQEzfPrjS06t978garCAbwYp0RlJcoYAlIiEkvTPEpsGGwA9YJ23TIBIOWjz+eI3v/W8NVnAFrChXFCXlmiIUkRDicECbwbD+C09X9wBu1xC4lYkEiP+twQrCKUKNYIlIqGlzJhTuhT2r7K7khBSwRE4iGNs0AEQ5tchdREJQq2zP9wDfNkcBS+QkgnaRu0uL3EUkBCW38azD2qyAJRLUgnWRu0awRCQkGQOt+itgiQQ7t9OB02GCb4pQfbBEJFS17A8HNsHBHXZXUiMFLJFaiHQ5gnORu6YIRSQUterv+b41cLc5VsASqYVIlyPoRrAinZEawRKR0NS4i2dfwh1L7K6kRgpYIrUQ6XIG3SL3KFcUFVYFZZVldpciIuJb7ihI6wA7ltpdSY0UsERqIdIdnCNYgKYJRSQ0Ne0GO3+yu4oaKWCJ1EKUyxmUTxECmiYUkdDUpBvk74T83XZXUi0FLJFaiHQ7KA6yKcJIl0awRCSENe3m+R6g04QKWCK1EOlyaARLRCSQNOnq+b4zMBe6K2CJ1EIwLnI/sgZL+xGKSCiKSoTElrBntd2VVEsBS6QWooJwkXuUq2oEq1wjWCISolLawd61dldRLQUskVrwjGAFZ8DSCJaIhKyUdpC7HizL7kqOo4AlUgvB2skdNIIlIiEspR2U5EHBHrsrOY4ClkgtBGMfLC1yF5GQl9rO8z0ApwkVsERqIdLlpCTYRrBcWuQuIiEupSpg5a6zt45qKGCJ1EIwjmCpk7uIhLzEluCMhFyNYIkEpcOL3K0AXEhZE00RikjIczghuY1noXuAUcASqYVIl+evSjCNYqmTu4iEheQ2sO9nu6s4jgKWSC0EY8ByO9w4jVMjWCIS2hKawaHtdldxHAUskVqIcjsBgrKbuxa5i0hIS2gGxXlQWmB3JcdQwBKphSMjWMG2H6ErSn2wRCS0JTT3fD+4w946fkEBS6QWIoN0BCvKGaURLBEJbQlNPd8PbrO3jl9QwBKphcMjWMVBNoIV6YrUGiwRCW1HRrACax2WApZILRwOWPsKSskrKqOiMjjaNUQ5NUUoIiEuvmoEK8AWurvsLkAkGMRFev6qTHh5PgCxEU7aNY7Haeys6uS2RJWwkZ1c+uz3dpcSFmIjXUy8rp/dZYiEl4gYiEoKuBEsBSyRWujRMol/jOxKfkkFlmWxeV8hP+8NrCdWquMykVimlNhI/VVvCLER+t9ZxBYJzRWwRIKRy+lgdJ9WdpdRZ7fPTmd34W4mXqhRFREJYQnNAm6RuwKWSAjLapxFbnGu3WWIiPhXQlPYscTuKo6hgCUSwq7ucrXdJYiI+F98MyjYDRVl4HTbXQ2gpwhFREQk2MUke74X59lbx1EUsERERCS4RSV5vhcdsLOKYyhgiYiISHCLTvJ8Lz5gZxXHUMASERGR4BaV6PmuESwRERERHzk8RagRLBEREREf0RShiIiIiI9pkbuIiIiIj7mjwBWlESwRERERn4pK0giWiIiIiE9FJWoES0RERMSnopPUyV1ERETEpzRFKCIiIuJj0UmaIhQRERHxqagkKNIUoYiIiIjvRCdBSR5UVthdCaCAJSIiIqHg8H6EJQftraOKApaIiIgEvwDr5q6AJSIiIsEvwPYjVMASERGR4BeZ4PleHAJThMaYy40xy40xlcaYrKNeP8cYs8AY81PV9yH1L1VERESkBu5oz/fyEnvrqOKq5/nLgEuB//7i9b3AhZZlbTfGdAFmAs3reS8RERGR6rkiPd/Li+2to0q9ApZlWSsBjDG/fH3RUT8uB6KNMZGWZQVGrBQREZHQ4oryfA+QEayGWIM1EliocCUiIiJ+E2wjWMaYWUCTat56wLKs909ybmfgH8C5JzjmRuBGgFatWp2sHBEREZHjHRnBCpKAZVnW2d5c2BjTApgOTLAsa/0Jrv888DxAVlaW5c29REREJMyFwxShMSYJ+Ai417Ks7/1xDxEREZEjAmwEq75tGi4xxmwFsoGPjDEzq966HWgHPGiMWVz1lV7PWkVERESq53QDJmBGsOr7FOF0PNOAv3z9L8Bf6nNtERERkVozxjOKVV5kdyWAOrmLiIhIqHBFBswIlgKWiIiIhAZXVGiswRIREREJGBrBEhEREfExjWCJiIiI+Jg7SiNYIiIiIj6lESwRERERH9MaLBEREREf0wiWiIiIiI+5IqFMAUtERETEdzSCJSIiIuJjWoMlIiIi4mMawRIRERHxMZf6YImIiIj4lkawRERERHzMFQVWBVSU212JApaIiIiECFek53sAjGIpYImIiEhocEV5vgfAOiwFLBEREQkNR0awiuytAwUsERERCRUawRIRERHxMa3BEhEREfGxIyNYClgiIiIivuHWFKGIiIiIb2kES0RERMTHjqzB0giWiIiIiG9oBEtERETExw6PYJUpYImIiIj4hkawRERERHxMjUZFREREfOzwFOGiifDtY7aWooAlIiIiocEdA+3Pg4pSOLDZ1lJctt5dRERExFeMgSvftLsKQCNYIiIiIj6ngCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj6mgCUiIiLiYwpYIiIiIj5mLMuyu4YjjDF7gE0NcKtUYG8D3Efsp886fOizDh/6rMNHoH/WGZZlpVX3RkAFrIZijMmxLCvL7jrE//RZhw991uFDn3X4CObPWlOEIiIiIj6mgCUiIiLiY+EasJ63uwBpMPqsw4c+6/Chzzp8BO1nHZZrsERERET8KVxHsERERET8JqwCljFmmDFmtTFmnTHmXrvrkfozxrxsjNltjFl21GvJxpjPjTFrq743qnrdGGOeqvr8lxpjetlXudSFMaalMeZLY8wKY8xyY8xdVa/rsw4xxpgoY8x8Y8ySqs/6j1WvtzbGzKv6TN8yxkRUvR5Z9fO6qvczbf0FpM6MMU5jzCJjzIdVP4fEZx02AcsY4wSeAc4DOgFXGGM62VuV+MCrwLBfvHYvMNuyrFOA2VU/g+ezP6Xq60bgPw1Uo9RfOXC3ZVmdgP7AbVV/f/VZh54SYIhlWd2BHsAwY0x/4B/A45ZltQP2A9dVHX8dsL/q9cerjpPgchew8qifQ+KzDpuABfQF1lmWtcGyrFLgTeAim2uSerIs6xtg3y9evgh4rerPrwEXH/X665bHXCDJGNO0QQqVerEsa4dlWQur/nwIz/8ZN0efdcip+szyq350V31ZwBDg7arXf/lZH/5n4G3gLGOMaZhqpb6MMS2AC4AXq342hMhnHU4Bqzmw5aift1a9JqGnsWVZO6r+vBNoXPVn/TMQAqqmBXoC89BnHZKqpowWA7uBz4H1wAHLssqrDjn68zzyWVe9nwekNGjBUh9PAL8FKqt+TiFEPutwClgShizPY7J6VDZEGGPigHeA/7Ms6+DR7+mzDh2WZVVYltUDaIFn9qGDvRWJPxhjhgO7LctaYHct/hBOAWsb0PKon1tUvSahZ9fh6aCq77urXtc/A0HMGOPGE64mW5b1btXL+qxDmGVZB4AvgWw807yuqreO/jyPfNZV7ycCuQ1bqXhpADDCGLMRz7KdIcCThMhnHU4B60fglKqnEyKAMcAMm2sS/5gBXFX156uA9496fULVE2b9gbyjppckgFWts3gJWGlZ1r+OekufdYgxxqQZY5Kq/hwNnINnzd2XwGVVh/3ysz78z8BlwBeWGjwGBcuy7rMsq4VlWZl4/p38hWVZYwmRzzqsGo0aY87HM9/rBF62LOtheyuS+jLGvAEMwrPj+i7gIeA9YCrQCtgEjLIsa1/Vv6SfxvPUYSFwjWVZOTaULXVkjDkd+Bb4if+t1bgfzzosfdYhxBjTDc9CZieeQYCplmX9yRjTBs8oRzKwCBhnWVaJMSYKmIhnXd4+YIxlWRvsqV68ZYwZBNxjWdbwUPmswypgiYiIiDSEcJoiFBEREWkQClgiIiIiPqaAJSIiIuJjClgiIiIiPqaAJSIiIuJjClgiIiIiPqaAJSIiIuJjClgiIiIiPvb/AZPpOMHoekM3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "plt.plot(np.log10(np.array(fx_int)), label='int')\n",
    "plt.plot(np.log10(np.array(fx_frac)), label='frac')\n",
    "plt.plot(np.log10(np.array(fx_multi_frac)), label='multi')\n",
    "plt.plot(np.log10(np.array(fx_dist_frac)), label='dist')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "import pickle \n",
    "import os\n",
    "from grads import grads\n",
    "from operators import operators\n",
    "from models.resnet import ResNet18\n",
    "from tqdm import tqdm\n",
    "# Define model\n",
    "def init_model(args):\n",
    "    if args.torch:\n",
    "        from torch.optim.rmsprop import RMSprop as RMSProp\n",
    "        from torch.optim.adam import Adam\n",
    "        from torch.optim.adagrad import Adagrad as AdaGrad\n",
    "        from torch.optim.sgd import SGD\n",
    "    else:\n",
    "        from pytorch_optim import SGD, AdaGrad, RMSProp, Adam\n",
    "\n",
    "    if args.model == 'fc1':\n",
    "        model = Net(1, 2)\n",
    "    if args.model == 'resnet18':\n",
    "        model = ResNet18(10)\n",
    "    model = model.to(args.device)\n",
    "    criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "    # criterion = nn.MSELoss().to(args.device)\n",
    "    \n",
    "    if args.grad == 'grad':\n",
    "        # G = grads.grad\n",
    "        G = torch.autograd.grad\n",
    "    elif args.grad == 'Ggamma':\n",
    "        G = grads.Ggamma\n",
    "    elif args.grad == 'Glearning_rate':\n",
    "        G = grads.Glearning_rate\n",
    "    elif args.grad == 'Reimann_Liouville':\n",
    "        G = grads.Reimann_Liouville\n",
    "    elif args.grad == 'Caputo':\n",
    "        G = grads.Caputo\n",
    "    elif args.grad == 'Reimann_Liouville_fromG':\n",
    "        G = grads.Reimann_Liouville_fromG\n",
    "    elif args.grad == 'Caputo_fromG':\n",
    "        G = grads.Caputo_fromG\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown gradient function: {args.grad}\")\n",
    "\n",
    "    OPT = operators(G, alpha1=args.alphas[0], alpha2=args.alphas[1])\n",
    "\n",
    "    if args.operator == \"integer\":\n",
    "        OPT = None\n",
    "    elif args.operator == \"fractional\":\n",
    "        OPT = OPT.fractional\n",
    "    elif args.operator == \"multi_fractional\":\n",
    "        OPT = OPT.multi_fractional\n",
    "    elif args.operator == \"distributed_fractional\":\n",
    "        OPT = OPT.distributed_fractional\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown operator: {args.operator}\")\n",
    "\n",
    "    if args.torch:\n",
    "        if args.optimizer == \"sgd\":\n",
    "            OPTIM = SGD(model.parameters(), lr=args.lr)\n",
    "        elif args.optimizer == \"adagrad\":\n",
    "            OPTIM = AdaGrad(model.parameters(), lr=args.lr)\n",
    "        elif args.optimizer == \"rmsprop\":\n",
    "            OPTIM = RMSProp(model.parameters(), lr=args.lr)\n",
    "        elif args.optimizer == \"adam\":\n",
    "            OPTIM = Adam(model.parameters(), lr=args.lr)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {args.optimizer}\")\n",
    "    else:\n",
    "        if args.optimizer == \"sgd\":\n",
    "            OPTIM = SGD(model.parameters(), OPT, lr=args.lr)\n",
    "        elif args.optimizer == \"adagrad\":\n",
    "            OPTIM = AdaGrad(model.parameters(), OPT, lr=args.lr)\n",
    "        elif args.optimizer == \"rmsprop\":\n",
    "            OPTIM = RMSProp(model.parameters(), OPT, lr=args.lr)\n",
    "        elif args.optimizer == \"adam\":\n",
    "            OPTIM = Adam(model.parameters(), OPT, lr=args.lr)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {args.optimizer}\")\n",
    "        \n",
    "    return OPTIM, model, criterion\n",
    "\n",
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        # self.fc1 = nn.Linear(input_size, output_size, bias=False)\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "        # self.relu1 = nn.ReLU()\n",
    "        # self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, 32*32*3)\n",
    "        out = self.fc1(x)\n",
    "        # out = self.relu1(out)\n",
    "        # out = self.fc3(out)\n",
    "        # out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "# def load_mnist():\n",
    "#     # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "#     transform = transforms.Compose([transforms.ToTensor()])\n",
    "#     train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "#     test_dataset = MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    \n",
    "#     train_size = int(0.8 * len(train_dataset))\n",
    "#     val_size = len(train_dataset) - train_size\n",
    "#     train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "    \n",
    "#     train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "#     val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "#     test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "#     return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "def load_cifar10():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = CIFAR10(root='D:/Datasets/data', train=True, transform=transform, download=True)\n",
    "    test_dataset = CIFAR10(root='D:/Datasets/data', train=False, transform=transform, download=True)\n",
    "    \n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, args, epochs=5):\n",
    "    pickle_saver={}\n",
    "    # save_path = f'./run/exp_{args.dataset}_{args.learning_rate}_{args.optimizer}_epochs_{epochs}/'\n",
    "    root_addr = f'./run/exp_{args.exp_idx}/'\n",
    "\n",
    "    while os.path.exists(root_addr):\n",
    "        args.exp_idx += 1\n",
    "        root_addr = root_addr.split('_')[0] + '_' +  str(args.exp_idx) + '/'\n",
    "        \n",
    "    os.makedirs(root_addr)\n",
    "    print(root_addr)\n",
    "    save_path = root_addr + f'cifar10_{args.model}_{args.lr}_{args.optimizer}_epochs_{epochs}_{args.operator}_alpha1_{args.alphas[0]}_alpha2_{args.alphas[1]}/'\n",
    "    model_save_path = os.path.join(save_path, 'models')\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        batch_time = []\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images = images.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            s = time.time()\n",
    "            loss.backward(create_graph=True)\n",
    "            optimizer.step()\n",
    "            e = time.time()\n",
    "            batch_time.append(e-s)\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {np.mean(train_loss):.16f}, Accuracy: {accuracy:.2f}%, batch mean time: {np.mean(batch_time)}, epoch optimization time: {np.sum(batch_time)}')\n",
    "        pickle_saver[epoch+1] = {'batch_time': batch_time, 'train_loss': train_loss, 'accuracy': accuracy}\n",
    "\n",
    "    save_results(pickle_saver, filename=os.path.join(save_path, 'training_results.pkl'))\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def save_results(results, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(results, file)\n",
    "\n",
    "# Validate the model\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.view(-1, 28*28)\n",
    "            labels = torch.nn.functional.one_hot(labels, num_classes=10).float()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    te_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(-1, 28*28)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            te_loss += loss.item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "    return te_loss/len(test_loader)\n",
    "\n",
    "\n",
    "def display_loss(train_loss):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_loss) + 1), train_loss, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(1, len(train_loss) + 1))  # To show all epochs on x-axis\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from torch.optim import SGD as psgd\n",
    "    \n",
    "def main():\n",
    "       \n",
    "    grad_funcs = ['grad', 'Ggamma', 'Glearning_rate', 'Reimann_Liouville', 'Caputo', 'Reimann_Liouville_fromG', 'Caputo_fromG']\n",
    "    opers = ['integer', 'fractional', 'multi_fractional', 'distributed_fractional']\n",
    "    optims = ['sgd', 'adagrad', 'rmsprop', 'adam']\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--lr', default=0.1, type=float)\n",
    "    parser.add_argument('--grad', default='grad', choices=grad_funcs)\n",
    "    parser.add_argument('--operator', default='multi_fractional', choices=opers)\n",
    "    parser.add_argument('--optimizer', default='sgd', choices=optims)\n",
    "    parser.add_argument('--model', default='fc1')\n",
    "    parser.add_argument('--alphas', type=str, default=\"[0.9, 1.1]\")\n",
    "    parser.add_argument('--exp_idx', type=int, default=0)\n",
    "    parser.add_argument('--device', type=str, default='cuda')\n",
    "    parser.add_argument('--torch', action=\"store_true\")\n",
    "    parser.add_argument('--gpu', type=int, default=0)\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    args.alphas = [float(x) for x in eval(args.alphas)]\n",
    "    my_seed = 1\n",
    "    import random\n",
    "    torch.manual_seed(my_seed)\n",
    "    np.random.seed(my_seed)\n",
    "    random.seed(my_seed)\n",
    "    \n",
    "    if args.device == 'cuda':    \n",
    "        os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "        args.device=f'cuda:{args.gpu}'\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_cifar10()\n",
    "    \n",
    "    input_size = 32 * 32 * 3  # CIFAR-10 image size (32x32) with 3 color channels\n",
    "    hidden_size = 256\n",
    "    output_size = 10\n",
    "\n",
    "    return args\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['', '--operator', 'distributed_fractional', '--device', 'cuda', '--optimizer', 'adam']\n",
    "args = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, model, criterion = init_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = torch.cat([torch.ones((500000, 1)), torch.ones((500000, 1)) * 2])\n",
    "        self.label = torch.cat([torch.zeros(500000).long(), torch.ones(500000).long()])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]            \n",
    "        l = self.label[idx]            \n",
    "        return img, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset()\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15625/15625 [03:08<00:00, 83.11it/s]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = []\n",
    "batch_time = []\n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in tqdm(train_loader):\n",
    "    images = images.to(args.device)\n",
    "    labels = labels.to(args.device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    s = time.time()\n",
    "    loss.backward(create_graph=True)\n",
    "    optimizer.step()\n",
    "    e = time.time()\n",
    "    batch_time.append(e-s)\n",
    "    train_loss.append(loss.item())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-13.9830],\n",
      "        [ 14.1397]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 20.7708, -21.2130], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for params in model.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6.7878, -7.0733], device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " tensor([1.0000e+00, 9.5534e-07], device='cuda:0', grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([1.]).to(args.device)), softmax(model(torch.tensor([1.]).to(args.device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-7.1951,  7.0663], device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " tensor([6.4020e-07, 1.0000e+00], device='cuda:0', grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([2.]).to(args.device)), softmax(model(torch.tensor([2.]).to(args.device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
